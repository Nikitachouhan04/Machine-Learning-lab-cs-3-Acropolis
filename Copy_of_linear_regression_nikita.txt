{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copy of linear regression-nikita",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJM8ymxD96uR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " class MyLinearRegression:\n",
        "    def __init__(self, weight=0  , bias=1    , learning_rate=0.001   ,\n",
        "                 iterations= 1000  ):\n",
        "        self.weight = weight\n",
        "        self.bias = bias\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations = iterations\n",
        "        self.cost_trend = []\n",
        "        self.cost = 0\n",
        "\n",
        "    def predict(self, x):\n",
        "        predicted_set = []\n",
        "        for i in range(len(x)):\n",
        "            predicted_value = self.weight * x[i] + self.bias\n",
        "            predicted_set.append(predicted_value)\n",
        "        return predicted_set\n",
        "\n",
        "    def cost_function(self, x, y):\n",
        "        count = len(x)\n",
        "        total_error = 0.0\n",
        "        for i in range(count):\n",
        "            total_error += (y[i] - (self.weight * x[i] +\n",
        "                            self.bias)) ** 2\n",
        "        return float(total_error) / (2 * count)\n",
        "\n",
        "    def update_weights(self, x, y):\n",
        "        weight_deriv = 0\n",
        "        bias_deriv = 0\n",
        "        count = len(x)\n",
        "\n",
        "        for i in range(count):\n",
        "            # Calculate partial derivatives\n",
        "            # -2x(y - (mx + b))\n",
        "            weight_deriv += -2 * x[i] * (y[i] -(self.weight * x[i] + self.bias))\n",
        "\n",
        "            # -2(y - (mx + b))\n",
        "            bias_deriv += -2 * (y[i] - (self.weight * x[i] +\n",
        "                                self.bias))\n",
        "\n",
        "        # We subtract because the derivatives point in direction of steepest\n",
        "        # ascent\n",
        "        self.weight -= (weight_deriv / count) * self.learning_rate\n",
        "        self.bias -= (bias_deriv / count) * self.learning_rate\n",
        "\n",
        "    def train(self, x, y):\n",
        "        for i in range(self.iterations):\n",
        "            self.update_weights(x, y)\n",
        "            # Calculating cost\n",
        "            self.cost = self.cost_function(x, y)\n",
        "            self.cost_trend.append(self.cost)\n",
        "           # if i % 10000 == 0:\n",
        "            print(\"Iteration: {}\\t Weight: {}\\t Bias: {}\\t Cost: {}\".format(i, self.weight, self.bias, self.cost))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGMUmPfj96ua",
        "colab_type": "code",
        "outputId": "fa9a8d4b-9e0c-4701-abcb-7bef55120085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# intialise data of lists. \n",
        "data = {'Hours':[2.5,5.1,3.2,8.5,3.5,1.5,9.2,5.5,8.3,2.7,7.7,5.9,4.5,3.3,1.1,8.9,2.5,1.9,6.1,7.4,2.7,4.8,3.8,6.9,7.8], \n",
        "        'Scores':[21,47,27,75,30,20,88,60,81,25,85,62,41,42,17,95,30,24,67,69,30,54,35,76,86]} \n",
        "  \n",
        "# Create DataFrame \n",
        "studentscores = pd.DataFrame(data) \n",
        "  \n",
        "# Print the output. \n",
        "studentscores "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hours</th>\n",
              "      <th>Scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.5</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.1</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.2</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.5</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.5</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.5</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9.2</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.5</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8.3</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.7</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.7</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5.9</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.5</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.3</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.1</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>8.9</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2.5</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.9</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.1</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7.4</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2.7</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4.8</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3.8</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.9</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>7.8</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Hours  Scores\n",
              "0     2.5      21\n",
              "1     5.1      47\n",
              "2     3.2      27\n",
              "3     8.5      75\n",
              "4     3.5      30\n",
              "5     1.5      20\n",
              "6     9.2      88\n",
              "7     5.5      60\n",
              "8     8.3      81\n",
              "9     2.7      25\n",
              "10    7.7      85\n",
              "11    5.9      62\n",
              "12    4.5      41\n",
              "13    3.3      42\n",
              "14    1.1      17\n",
              "15    8.9      95\n",
              "16    2.5      30\n",
              "17    1.9      24\n",
              "18    6.1      67\n",
              "19    7.4      69\n",
              "20    2.7      30\n",
              "21    4.8      54\n",
              "22    3.8      35\n",
              "23    6.9      76\n",
              "24    7.8      86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avh401TI11sH",
        "colab_type": "code",
        "outputId": "f4ec1f6f-6b94-4d88-833d-1bed920f343d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "x=[2.5,5.1,3.2,8.5,3.5,1.5,9.2,5.5,8.3,2.7,7.7,5.9,4.5,3.3,1.1,8.9,2.5,1.9,6.1,7.4,2.7,4.8,3.8,6.9,7.8] \n",
        "y=[21,47,27,75,30,20,88,60,81,25,85,62,41,42,17,95,30,24,67,69,30,54,35,76,86]\n",
        "plt.scatter(x,y,s=10)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nesbgl6SeMfglqWf+PyxzPdxnrKOcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LSp2jKt96uj",
        "colab_type": "code",
        "outputId": "28123ea0-0b61-4c5e-ab65-4cc8e544e7bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "#from my_linear_regression import MyLinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importing the dataset\n",
        "\n",
        "X = studentscores.iloc[:, :-1].values\n",
        "y = studentscores.iloc[:, -1].values\n",
        "X,y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[2.5],\n",
              "        [5.1],\n",
              "        [3.2],\n",
              "        [8.5],\n",
              "        [3.5],\n",
              "        [1.5],\n",
              "        [9.2],\n",
              "        [5.5],\n",
              "        [8.3],\n",
              "        [2.7],\n",
              "        [7.7],\n",
              "        [5.9],\n",
              "        [4.5],\n",
              "        [3.3],\n",
              "        [1.1],\n",
              "        [8.9],\n",
              "        [2.5],\n",
              "        [1.9],\n",
              "        [6.1],\n",
              "        [7.4],\n",
              "        [2.7],\n",
              "        [4.8],\n",
              "        [3.8],\n",
              "        [6.9],\n",
              "        [7.8]]),\n",
              " array([21, 47, 27, 75, 30, 20, 88, 60, 81, 25, 85, 62, 41, 42, 17, 95, 30,\n",
              "        24, 67, 69, 30, 54, 35, 76, 86]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvfKE_WT96un",
        "colab_type": "code",
        "outputId": "1f0afd54-7709-4738-9e35-a040b99126ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)\n",
        "\n",
        "# Fitting Simple Linear Regression to the Training set\n",
        "regressor = MyLinearRegression()\n",
        "regressor.train(X_train, y_train)\n",
        "\n",
        "plt.plot(regressor.cost_trend);\n",
        "plt.show()\n",
        "print('Weight: ' + str(regressor.weight) + ' Bias: ' + str(regressor.bias))\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = regressor.predict(X_test)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0\t Weight: [0.67755]\t Bias: [1.10525]\t Cost: 1469.8295341079859\n",
            "Iteration: 1\t Weight: [1.30772819]\t Bias: [1.20314135]\t Cost: 1273.5847678071568\n",
            "Iteration: 2\t Weight: [1.89384664]\t Bias: [1.29418853]\t Cost: 1103.822122933581\n",
            "Iteration: 3\t Weight: [2.43898584]\t Bias: [1.37887007]\t Cost: 956.9679869598637\n",
            "Iteration: 4\t Weight: [2.9460109]\t Bias: [1.45763103]\t Cost: 829.9309861600221\n",
            "Iteration: 5\t Weight: [3.41758664]\t Bias: [1.53088536]\t Cost: 720.0369102103487\n",
            "Iteration: 6\t Weight: [3.85619152]\t Bias: [1.59901805]\t Cost: 624.9724183473763\n",
            "Iteration: 7\t Weight: [4.26413077]\t Bias: [1.66238719]\t Cost: 542.7363420614795\n",
            "Iteration: 8\t Weight: [4.64354839]\t Bias: [1.72132584]\t Cost: 471.59755921658586\n",
            "Iteration: 9\t Weight: [4.99643853]\t Bias: [1.77614375]\t Cost: 410.0585528192067\n",
            "Iteration: 10\t Weight: [5.32465588]\t Bias: [1.82712903]\t Cost: 356.8238873255064\n",
            "Iteration: 11\t Weight: [5.62992548]\t Bias: [1.87454966]\t Cost: 310.77293889246454\n",
            "Iteration: 12\t Weight: [5.91385174]\t Bias: [1.91865484]\t Cost: 270.936305527429\n",
            "Iteration: 13\t Weight: [6.17792692]\t Bias: [1.9596764]\t Cost: 236.47540055458478\n",
            "Iteration: 14\t Weight: [6.42353893]\t Bias: [1.99782992]\t Cost: 206.66479982772157\n",
            "Iteration: 15\t Weight: [6.65197865]\t Bias: [2.03331592]\t Cost: 180.87697108680896\n",
            "Iteration: 16\t Weight: [6.86444669]\t Bias: [2.06632091]\t Cost: 158.56906400154645\n",
            "Iteration: 17\t Weight: [7.06205975]\t Bias: [2.09701836]\t Cost: 139.271482823831\n",
            "Iteration: 18\t Weight: [7.24585642]\t Bias: [2.12556959]\t Cost: 122.57800109615224\n",
            "Iteration: 19\t Weight: [7.4168027]\t Bias: [2.15212467]\t Cost: 108.13721032418707\n",
            "Iteration: 20\t Weight: [7.57579704]\t Bias: [2.17682315]\t Cost: 95.64512260266886\n",
            "Iteration: 21\t Weight: [7.72367507]\t Bias: [2.19979485]\t Cost: 84.83877147506279\n",
            "Iteration: 22\t Weight: [7.86121401]\t Bias: [2.22116048]\t Cost: 75.49067632104004\n",
            "Iteration: 23\t Weight: [7.98913673]\t Bias: [2.24103235]\t Cost: 67.40405374355822\n",
            "Iteration: 24\t Weight: [8.10811555]\t Bias: [2.2595149]\t Cost: 60.40867515217464\n",
            "Iteration: 25\t Weight: [8.21877581]\t Bias: [2.27670525]\t Cost: 54.357283342066154\n",
            "Iteration: 26\t Weight: [8.3216991]\t Bias: [2.29269375]\t Cost: 49.122492635445404\n",
            "Iteration: 27\t Weight: [8.41742638]\t Bias: [2.30756444]\t Cost: 44.59410733136268\n",
            "Iteration: 28\t Weight: [8.50646074]\t Bias: [2.32139546]\t Cost: 40.67680201554323\n",
            "Iteration: 29\t Weight: [8.58927015]\t Bias: [2.33425951]\t Cost: 37.288114899293284\n",
            "Iteration: 30\t Weight: [8.66628982]\t Bias: [2.34622419]\t Cost: 34.356711945973075\n",
            "Iteration: 31\t Weight: [8.73792455]\t Bias: [2.35735239]\t Cost: 31.82088524378577\n",
            "Iteration: 32\t Weight: [8.80455084]\t Bias: [2.36770258]\t Cost: 29.627254014666786\n",
            "Iteration: 33\t Weight: [8.86651885]\t Bias: [2.37732916]\t Cost: 27.729640914677322\n",
            "Iteration: 34\t Weight: [8.92415429]\t Bias: [2.38628273]\t Cost: 26.08809997130541\n",
            "Iteration: 35\t Weight: [8.97776006]\t Bias: [2.39461034]\t Cost: 24.66807569513078\n",
            "Iteration: 36\t Weight: [9.02761791]\t Bias: [2.40235575]\t Cost: 23.439675664615493\n",
            "Iteration: 37\t Weight: [9.07398988]\t Bias: [2.40955967]\t Cost: 22.37704127146332\n",
            "Iteration: 38\t Weight: [9.11711968]\t Bias: [2.41625995]\t Cost: 21.457803380334404\n",
            "Iteration: 39\t Weight: [9.157234]\t Bias: [2.42249182]\t Cost: 20.662611444203264\n",
            "Iteration: 40\t Weight: [9.19454366]\t Bias: [2.42828802]\t Cost: 19.974726162935948\n",
            "Iteration: 41\t Weight: [9.22924477]\t Bias: [2.43367901]\t Cost: 19.379667110289184\n",
            "Iteration: 42\t Weight: [9.2615197]\t Bias: [2.43869312]\t Cost: 18.864907911652814\n",
            "Iteration: 43\t Weight: [9.29153807]\t Bias: [2.4433567]\t Cost: 18.419612555832405\n",
            "Iteration: 44\t Weight: [9.31945767]\t Bias: [2.44769426]\t Cost: 18.034407290065342\n",
            "Iteration: 45\t Weight: [9.34542522]\t Bias: [2.45172859]\t Cost: 17.701183296514767\n",
            "Iteration: 46\t Weight: [9.36957722]\t Bias: [2.4554809]\t Cost: 17.412925996454756\n",
            "Iteration: 47\t Weight: [9.39204058]\t Bias: [2.4589709]\t Cost: 17.163567388890193\n",
            "Iteration: 48\t Weight: [9.41293339]\t Bias: [2.46221693]\t Cost: 16.94785831524505\n",
            "Iteration: 49\t Weight: [9.43236544]\t Bias: [2.46523604]\t Cost: 16.76125796120863\n",
            "Iteration: 50\t Weight: [9.45043887]\t Bias: [2.46804412]\t Cost: 16.59983826968266\n",
            "Iteration: 51\t Weight: [9.46724867]\t Bias: [2.4706559]\t Cost: 16.460201252660667\n",
            "Iteration: 52\t Weight: [9.48288317]\t Bias: [2.47308511]\t Cost: 16.339407461401738\n",
            "Iteration: 53\t Weight: [9.49742457]\t Bias: [2.47534453]\t Cost: 16.234914109149578\n",
            "Iteration: 54\t Weight: [9.51094928]\t Bias: [2.47744601]\t Cost: 16.14452154384097\n",
            "Iteration: 55\t Weight: [9.52352839]\t Bias: [2.4794006]\t Cost: 16.066326944019337\n",
            "Iteration: 56\t Weight: [9.535228]\t Bias: [2.48121857]\t Cost: 15.998684263223023\n",
            "Iteration: 57\t Weight: [9.54610961]\t Bias: [2.48290948]\t Cost: 15.940169579651801\n",
            "Iteration: 58\t Weight: [9.55623042]\t Bias: [2.48448221]\t Cost: 15.889551121699952\n",
            "Iteration: 59\t Weight: [9.56564361]\t Bias: [2.48594501]\t Cost: 15.845763338374168\n",
            "Iteration: 60\t Weight: [9.57439866]\t Bias: [2.48730558]\t Cost: 15.80788446876184\n",
            "Iteration: 61\t Weight: [9.58254158]\t Bias: [2.48857106]\t Cost: 15.77511713837292\n",
            "Iteration: 62\t Weight: [9.59011517]\t Bias: [2.48974811]\t Cost: 15.746771573895511\n",
            "Iteration: 63\t Weight: [9.59715924]\t Bias: [2.4908429]\t Cost: 15.722251083025409\n",
            "Iteration: 64\t Weight: [9.60371081]\t Bias: [2.49186118]\t Cost: 15.701039493710544\n",
            "Iteration: 65\t Weight: [9.60980431]\t Bias: [2.49280831]\t Cost: 15.682690288398229\n",
            "Iteration: 66\t Weight: [9.61547177]\t Bias: [2.49368926]\t Cost: 15.666817204554437\n",
            "Iteration: 67\t Weight: [9.62074297]\t Bias: [2.49450865]\t Cost: 15.653086103589718\n",
            "Iteration: 68\t Weight: [9.62564563]\t Bias: [2.4952708]\t Cost: 15.641207937027714\n",
            "Iteration: 69\t Weight: [9.6302055]\t Bias: [2.49597969]\t Cost: 15.630932661849322\n",
            "Iteration: 70\t Weight: [9.63444656]\t Bias: [2.49663907]\t Cost: 15.622043976926875\n",
            "Iteration: 71\t Weight: [9.63839109]\t Bias: [2.49725238]\t Cost: 15.614354769746647\n",
            "Iteration: 72\t Weight: [9.64205983]\t Bias: [2.49782285]\t Cost: 15.607703177570539\n",
            "Iteration: 73\t Weight: [9.64547206]\t Bias: [2.49835347]\t Cost: 15.601949180121549\n",
            "Iteration: 74\t Weight: [9.64864571]\t Bias: [2.49884703]\t Cost: 15.596971652067294\n",
            "Iteration: 75\t Weight: [9.65159747]\t Bias: [2.49930613]\t Cost: 15.592665813253971\n",
            "Iteration: 76\t Weight: [9.65434284]\t Bias: [2.49973316]\t Cost: 15.588941023017002\n",
            "Iteration: 77\t Weight: [9.65689626]\t Bias: [2.50013038]\t Cost: 15.585718872136937\n",
            "Iteration: 78\t Weight: [9.65927115]\t Bias: [2.50049986]\t Cost: 15.582931532275033\n",
            "Iteration: 79\t Weight: [9.66147999]\t Bias: [2.50084355]\t Cost: 15.580520328143315\n",
            "Iteration: 80\t Weight: [9.6635344]\t Bias: [2.50116325]\t Cost: 15.5784345023521\n",
            "Iteration: 81\t Weight: [9.66544515]\t Bias: [2.50146063]\t Cost: 15.576630146934402\n",
            "Iteration: 82\t Weight: [9.66722231]\t Bias: [2.50173727]\t Cost: 15.57506927905507\n",
            "Iteration: 83\t Weight: [9.66887521]\t Bias: [2.5019946]\t Cost: 15.573719041447777\n",
            "Iteration: 84\t Weight: [9.67041254]\t Bias: [2.50223397]\t Cost: 15.572551010748445\n",
            "Iteration: 85\t Weight: [9.67184238]\t Bias: [2.50245665]\t Cost: 15.571540599165274\n",
            "Iteration: 86\t Weight: [9.67317225]\t Bias: [2.5026638]\t Cost: 15.570666536889897\n",
            "Iteration: 87\t Weight: [9.67440912]\t Bias: [2.50285651]\t Cost: 15.569910424354317\n",
            "Iteration: 88\t Weight: [9.67555952]\t Bias: [2.50303578]\t Cost: 15.56925634490819\n",
            "Iteration: 89\t Weight: [9.67662948]\t Bias: [2.50320256]\t Cost: 15.568690529763103\n",
            "Iteration: 90\t Weight: [9.67762462]\t Bias: [2.50335771]\t Cost: 15.568201068150799\n",
            "Iteration: 91\t Weight: [9.67855018]\t Bias: [2.50350205]\t Cost: 15.56777765659383\n",
            "Iteration: 92\t Weight: [9.67941102]\t Bias: [2.50363635]\t Cost: 15.567411382010766\n",
            "Iteration: 93\t Weight: [9.68021168]\t Bias: [2.50376129]\t Cost: 15.5670945340901\n",
            "Iteration: 94\t Weight: [9.68095634]\t Bias: [2.50387753]\t Cost: 15.566820442983284\n",
            "Iteration: 95\t Weight: [9.68164894]\t Bias: [2.50398569]\t Cost: 15.56658333890009\n",
            "Iteration: 96\t Weight: [9.6822931]\t Bias: [2.50408632]\t Cost: 15.566378230650859\n",
            "Iteration: 97\t Weight: [9.68289222]\t Bias: [2.50417995]\t Cost: 15.566200800578748\n",
            "Iteration: 98\t Weight: [9.68344945]\t Bias: [2.50426708]\t Cost: 15.566047313670325\n",
            "Iteration: 99\t Weight: [9.68396771]\t Bias: [2.50434816]\t Cost: 15.565914538931027\n",
            "Iteration: 100\t Weight: [9.68444974]\t Bias: [2.5044236]\t Cost: 15.565799681370793\n",
            "Iteration: 101\t Weight: [9.68489805]\t Bias: [2.50449381]\t Cost: 15.56570032316765\n",
            "Iteration: 102\t Weight: [9.68531501]\t Bias: [2.50455915]\t Cost: 15.565614372771016\n",
            "Iteration: 103\t Weight: [9.68570282]\t Bias: [2.50461995]\t Cost: 15.56554002087325\n",
            "Iteration: 104\t Weight: [9.6860635]\t Bias: [2.50467655]\t Cost: 15.565475702322527\n",
            "Iteration: 105\t Weight: [9.68639897]\t Bias: [2.50472923]\t Cost: 15.565420063175422\n",
            "Iteration: 106\t Weight: [9.68671097]\t Bias: [2.50477826]\t Cost: 15.56537193219551\n",
            "Iteration: 107\t Weight: [9.68700115]\t Bias: [2.5048239]\t Cost: 15.565330296198107\n",
            "Iteration: 108\t Weight: [9.68727104]\t Bias: [2.50486639]\t Cost: 15.565294278722082\n",
            "Iteration: 109\t Weight: [9.68752205]\t Bias: [2.50490595]\t Cost: 15.565263121579743\n",
            "Iteration: 110\t Weight: [9.6877555]\t Bias: [2.50494278]\t Cost: 15.565236168896554\n",
            "Iteration: 111\t Weight: [9.68797263]\t Bias: [2.50497707]\t Cost: 15.565212853304585\n",
            "Iteration: 112\t Weight: [9.68817457]\t Bias: [2.50500901]\t Cost: 15.565192683998903\n",
            "Iteration: 113\t Weight: [9.68836239]\t Bias: [2.50503875]\t Cost: 15.565175236406043\n",
            "Iteration: 114\t Weight: [9.68853706]\t Bias: [2.50506645]\t Cost: 15.565160143246217\n",
            "Iteration: 115\t Weight: [9.68869952]\t Bias: [2.50509225]\t Cost: 15.565147086802023\n",
            "Iteration: 116\t Weight: [9.68885062]\t Bias: [2.50511628]\t Cost: 15.565135792230251\n",
            "Iteration: 117\t Weight: [9.68899114]\t Bias: [2.50513868]\t Cost: 15.565126021776164\n",
            "Iteration: 118\t Weight: [9.68912184]\t Bias: [2.50515954]\t Cost: 15.565117569768724\n",
            "Iteration: 119\t Weight: [9.68924339]\t Bias: [2.50517899]\t Cost: 15.565110258291028\n",
            "Iteration: 120\t Weight: [9.68935643]\t Bias: [2.50519711]\t Cost: 15.565103933435056\n",
            "Iteration: 121\t Weight: [9.68946157]\t Bias: [2.50521401]\t Cost: 15.565098462061801\n",
            "Iteration: 122\t Weight: [9.68955935]\t Bias: [2.50522976]\t Cost: 15.565093728998614\n",
            "Iteration: 123\t Weight: [9.68965029]\t Bias: [2.50524445]\t Cost: 15.565089634614727\n",
            "Iteration: 124\t Weight: [9.68973486]\t Bias: [2.50525815]\t Cost: 15.565086092724009\n",
            "Iteration: 125\t Weight: [9.68981352]\t Bias: [2.50527093]\t Cost: 15.565083028770625\n",
            "Iteration: 126\t Weight: [9.68988667]\t Bias: [2.50528286]\t Cost: 15.56508037825969\n",
            "Iteration: 127\t Weight: [9.68995469]\t Bias: [2.50529399]\t Cost: 15.565078085399469\n",
            "Iteration: 128\t Weight: [9.69001796]\t Bias: [2.50530438]\t Cost: 15.565076101927039\n",
            "Iteration: 129\t Weight: [9.6900768]\t Bias: [2.50531408]\t Cost: 15.565074386092288\n",
            "Iteration: 130\t Weight: [9.69013152]\t Bias: [2.50532314]\t Cost: 15.56507290177902\n",
            "Iteration: 131\t Weight: [9.6901824]\t Bias: [2.50533161]\t Cost: 15.565071617744767\n",
            "Iteration: 132\t Weight: [9.69022973]\t Bias: [2.50533952]\t Cost: 15.565070506963009\n",
            "Iteration: 133\t Weight: [9.69027373]\t Bias: [2.50534692]\t Cost: 15.565069546054318\n",
            "Iteration: 134\t Weight: [9.69031466]\t Bias: [2.50535384]\t Cost: 15.565068714794172\n",
            "Iteration: 135\t Weight: [9.69035272]\t Bias: [2.50536031]\t Cost: 15.565067995687262\n",
            "Iteration: 136\t Weight: [9.69038811]\t Bias: [2.50536637]\t Cost: 15.565067373599163\n",
            "Iteration: 137\t Weight: [9.69042102]\t Bias: [2.50537204]\t Cost: 15.565066835437745\n",
            "Iteration: 138\t Weight: [9.69045162]\t Bias: [2.50537735]\t Cost: 15.565066369877588\n",
            "Iteration: 139\t Weight: [9.69048008]\t Bias: [2.50538233]\t Cost: 15.565065967121564\n",
            "Iteration: 140\t Weight: [9.69050654]\t Bias: [2.505387]\t Cost: 15.56506561869465\n",
            "Iteration: 141\t Weight: [9.69053115]\t Bias: [2.50539139]\t Cost: 15.56506531726545\n",
            "Iteration: 142\t Weight: [9.69055403]\t Bias: [2.5053955]\t Cost: 15.565065056491887\n",
            "Iteration: 143\t Weight: [9.6905753]\t Bias: [2.50539936]\t Cost: 15.565064830887739\n",
            "Iteration: 144\t Weight: [9.69059509]\t Bias: [2.505403]\t Cost: 15.565064635707117\n",
            "Iteration: 145\t Weight: [9.69061348]\t Bias: [2.50540641]\t Cost: 15.565064466844536\n",
            "Iteration: 146\t Weight: [9.69063058]\t Bias: [2.50540963]\t Cost: 15.565064320748544\n",
            "Iteration: 147\t Weight: [9.69064648]\t Bias: [2.50541265]\t Cost: 15.565064194346942\n",
            "Iteration: 148\t Weight: [9.69066126]\t Bias: [2.50541551]\t Cost: 15.565064084982088\n",
            "Iteration: 149\t Weight: [9.690675]\t Bias: [2.5054182]\t Cost: 15.56506399035499\n",
            "Iteration: 150\t Weight: [9.69068778]\t Bias: [2.50542074]\t Cost: 15.565063908476889\n",
            "Iteration: 151\t Weight: [9.69069965]\t Bias: [2.50542315]\t Cost: 15.56506383762737\n",
            "Iteration: 152\t Weight: [9.69071069]\t Bias: [2.50542542]\t Cost: 15.565063776318242\n",
            "Iteration: 153\t Weight: [9.69072096]\t Bias: [2.50542757]\t Cost: 15.565063723262067\n",
            "Iteration: 154\t Weight: [9.6907305]\t Bias: [2.50542961]\t Cost: 15.56506367734519\n",
            "Iteration: 155\t Weight: [9.69073936]\t Bias: [2.50543154]\t Cost: 15.565063637604206\n",
            "Iteration: 156\t Weight: [9.6907476]\t Bias: [2.50543338]\t Cost: 15.565063603205726\n",
            "Iteration: 157\t Weight: [9.69075526]\t Bias: [2.50543513]\t Cost: 15.565063573428843\n",
            "Iteration: 158\t Weight: [9.69076238]\t Bias: [2.50543679]\t Cost: 15.565063547649888\n",
            "Iteration: 159\t Weight: [9.69076899]\t Bias: [2.50543837]\t Cost: 15.565063525329396\n",
            "Iteration: 160\t Weight: [9.69077514]\t Bias: [2.50543988]\t Cost: 15.565063506000664\n",
            "Iteration: 161\t Weight: [9.69078085]\t Bias: [2.50544132]\t Cost: 15.565063489260007\n",
            "Iteration: 162\t Weight: [9.69078615]\t Bias: [2.5054427]\t Cost: 15.565063474758176\n",
            "Iteration: 163\t Weight: [9.69079108]\t Bias: [2.50544402]\t Cost: 15.565063462193079\n",
            "Iteration: 164\t Weight: [9.69079566]\t Bias: [2.50544529]\t Cost: 15.565063451303384\n",
            "Iteration: 165\t Weight: [9.69079991]\t Bias: [2.50544651]\t Cost: 15.565063441863\n",
            "Iteration: 166\t Weight: [9.69080386]\t Bias: [2.50544767]\t Cost: 15.56506343367639\n",
            "Iteration: 167\t Weight: [9.69080752]\t Bias: [2.5054488]\t Cost: 15.565063426574353\n",
            "Iteration: 168\t Weight: [9.69081093]\t Bias: [2.50544988]\t Cost: 15.56506342041056\n",
            "Iteration: 169\t Weight: [9.69081409]\t Bias: [2.50545093]\t Cost: 15.565063415058415\n",
            "Iteration: 170\t Weight: [9.69081702]\t Bias: [2.50545193]\t Cost: 15.565063410408404\n",
            "Iteration: 171\t Weight: [9.69081975]\t Bias: [2.50545291]\t Cost: 15.565063406365805\n",
            "Iteration: 172\t Weight: [9.69082227]\t Bias: [2.50545386]\t Cost: 15.565063402848647\n",
            "Iteration: 173\t Weight: [9.69082462]\t Bias: [2.50545477]\t Cost: 15.565063399786041\n",
            "Iteration: 174\t Weight: [9.69082679]\t Bias: [2.50545567]\t Cost: 15.565063397116662\n",
            "Iteration: 175\t Weight: [9.69082881]\t Bias: [2.50545653]\t Cost: 15.565063394787474\n",
            "Iteration: 176\t Weight: [9.69083068]\t Bias: [2.50545737]\t Cost: 15.565063392752577\n",
            "Iteration: 177\t Weight: [9.69083241]\t Bias: [2.5054582]\t Cost: 15.565063390972272\n",
            "Iteration: 178\t Weight: [9.69083402]\t Bias: [2.505459]\t Cost: 15.56506338941222\n",
            "Iteration: 179\t Weight: [9.6908355]\t Bias: [2.50545978]\t Cost: 15.565063388042713\n",
            "Iteration: 180\t Weight: [9.69083688]\t Bias: [2.50546055]\t Cost: 15.56506338683804\n",
            "Iteration: 181\t Weight: [9.69083816]\t Bias: [2.5054613]\t Cost: 15.565063385775987\n",
            "Iteration: 182\t Weight: [9.69083934]\t Bias: [2.50546203]\t Cost: 15.565063384837318\n",
            "Iteration: 183\t Weight: [9.69084043]\t Bias: [2.50546275]\t Cost: 15.5650633840054\n",
            "Iteration: 184\t Weight: [9.69084144]\t Bias: [2.50546346]\t Cost: 15.565063383265846\n",
            "Iteration: 185\t Weight: [9.69084238]\t Bias: [2.50546416]\t Cost: 15.56506338260619\n",
            "Iteration: 186\t Weight: [9.69084324]\t Bias: [2.50546484]\t Cost: 15.565063382015678\n",
            "Iteration: 187\t Weight: [9.69084404]\t Bias: [2.50546551]\t Cost: 15.565063381484991\n",
            "Iteration: 188\t Weight: [9.69084477]\t Bias: [2.50546618]\t Cost: 15.565063381006075\n",
            "Iteration: 189\t Weight: [9.69084545]\t Bias: [2.50546683]\t Cost: 15.56506338057194\n",
            "Iteration: 190\t Weight: [9.69084607]\t Bias: [2.50546748]\t Cost: 15.56506338017659\n",
            "Iteration: 191\t Weight: [9.69084665]\t Bias: [2.50546812]\t Cost: 15.56506337981476\n",
            "Iteration: 192\t Weight: [9.69084718]\t Bias: [2.50546875]\t Cost: 15.565063379481982\n",
            "Iteration: 193\t Weight: [9.69084766]\t Bias: [2.50546938]\t Cost: 15.565063379174331\n",
            "Iteration: 194\t Weight: [9.69084811]\t Bias: [2.50546999]\t Cost: 15.56506337888844\n",
            "Iteration: 195\t Weight: [9.69084852]\t Bias: [2.50547061]\t Cost: 15.56506337862137\n",
            "Iteration: 196\t Weight: [9.6908489]\t Bias: [2.50547121]\t Cost: 15.565063378370622\n",
            "Iteration: 197\t Weight: [9.69084924]\t Bias: [2.50547182]\t Cost: 15.565063378133985\n",
            "Iteration: 198\t Weight: [9.69084955]\t Bias: [2.50547241]\t Cost: 15.565063377909569\n",
            "Iteration: 199\t Weight: [9.69084984]\t Bias: [2.50547301]\t Cost: 15.565063377695747\n",
            "Iteration: 200\t Weight: [9.6908501]\t Bias: [2.50547359]\t Cost: 15.565063377491112\n",
            "Iteration: 201\t Weight: [9.69085033]\t Bias: [2.50547418]\t Cost: 15.56506337729443\n",
            "Iteration: 202\t Weight: [9.69085055]\t Bias: [2.50547476]\t Cost: 15.56506337710463\n",
            "Iteration: 203\t Weight: [9.69085074]\t Bias: [2.50547534]\t Cost: 15.565063376920811\n",
            "Iteration: 204\t Weight: [9.69085091]\t Bias: [2.50547591]\t Cost: 15.565063376742188\n",
            "Iteration: 205\t Weight: [9.69085107]\t Bias: [2.50547648]\t Cost: 15.565063376568066\n",
            "Iteration: 206\t Weight: [9.69085121]\t Bias: [2.50547705]\t Cost: 15.565063376397838\n",
            "Iteration: 207\t Weight: [9.69085133]\t Bias: [2.50547761]\t Cost: 15.565063376231006\n",
            "Iteration: 208\t Weight: [9.69085144]\t Bias: [2.50547818]\t Cost: 15.565063376067124\n",
            "Iteration: 209\t Weight: [9.69085154]\t Bias: [2.50547874]\t Cost: 15.565063375905819\n",
            "Iteration: 210\t Weight: [9.69085162]\t Bias: [2.5054793]\t Cost: 15.56506337574673\n",
            "Iteration: 211\t Weight: [9.69085169]\t Bias: [2.50547985]\t Cost: 15.5650633755896\n",
            "Iteration: 212\t Weight: [9.69085175]\t Bias: [2.50548041]\t Cost: 15.565063375434159\n",
            "Iteration: 213\t Weight: [9.69085181]\t Bias: [2.50548096]\t Cost: 15.56506337528022\n",
            "Iteration: 214\t Weight: [9.69085185]\t Bias: [2.50548151]\t Cost: 15.565063375127565\n",
            "Iteration: 215\t Weight: [9.69085188]\t Bias: [2.50548206]\t Cost: 15.565063374976038\n",
            "Iteration: 216\t Weight: [9.69085191]\t Bias: [2.50548261]\t Cost: 15.565063374825508\n",
            "Iteration: 217\t Weight: [9.69085192]\t Bias: [2.50548316]\t Cost: 15.56506337467587\n",
            "Iteration: 218\t Weight: [9.69085193]\t Bias: [2.50548371]\t Cost: 15.565063374526995\n",
            "Iteration: 219\t Weight: [9.69085194]\t Bias: [2.50548425]\t Cost: 15.565063374378804\n",
            "Iteration: 220\t Weight: [9.69085194]\t Bias: [2.50548479]\t Cost: 15.565063374231205\n",
            "Iteration: 221\t Weight: [9.69085193]\t Bias: [2.50548534]\t Cost: 15.565063374084158\n",
            "Iteration: 222\t Weight: [9.69085192]\t Bias: [2.50548588]\t Cost: 15.565063373937583\n",
            "Iteration: 223\t Weight: [9.6908519]\t Bias: [2.50548642]\t Cost: 15.565063373791439\n",
            "Iteration: 224\t Weight: [9.69085188]\t Bias: [2.50548696]\t Cost: 15.565063373645671\n",
            "Iteration: 225\t Weight: [9.69085185]\t Bias: [2.5054875]\t Cost: 15.565063373500264\n",
            "Iteration: 226\t Weight: [9.69085182]\t Bias: [2.50548803]\t Cost: 15.565063373355152\n",
            "Iteration: 227\t Weight: [9.69085178]\t Bias: [2.50548857]\t Cost: 15.565063373210329\n",
            "Iteration: 228\t Weight: [9.69085175]\t Bias: [2.50548911]\t Cost: 15.565063373065776\n",
            "Iteration: 229\t Weight: [9.69085171]\t Bias: [2.50548964]\t Cost: 15.565063372921463\n",
            "Iteration: 230\t Weight: [9.69085166]\t Bias: [2.50549018]\t Cost: 15.565063372777356\n",
            "Iteration: 231\t Weight: [9.69085162]\t Bias: [2.50549071]\t Cost: 15.565063372633466\n",
            "Iteration: 232\t Weight: [9.69085157]\t Bias: [2.50549125]\t Cost: 15.565063372489773\n",
            "Iteration: 233\t Weight: [9.69085152]\t Bias: [2.50549178]\t Cost: 15.565063372346243\n",
            "Iteration: 234\t Weight: [9.69085147]\t Bias: [2.50549231]\t Cost: 15.56506337220288\n",
            "Iteration: 235\t Weight: [9.69085141]\t Bias: [2.50549285]\t Cost: 15.565063372059697\n",
            "Iteration: 236\t Weight: [9.69085135]\t Bias: [2.50549338]\t Cost: 15.56506337191664\n",
            "Iteration: 237\t Weight: [9.6908513]\t Bias: [2.50549391]\t Cost: 15.56506337177375\n",
            "Iteration: 238\t Weight: [9.69085124]\t Bias: [2.50549444]\t Cost: 15.565063371631\n",
            "Iteration: 239\t Weight: [9.69085117]\t Bias: [2.50549497]\t Cost: 15.565063371488375\n",
            "Iteration: 240\t Weight: [9.69085111]\t Bias: [2.5054955]\t Cost: 15.565063371345886\n",
            "Iteration: 241\t Weight: [9.69085105]\t Bias: [2.50549603]\t Cost: 15.565063371203518\n",
            "Iteration: 242\t Weight: [9.69085098]\t Bias: [2.50549656]\t Cost: 15.565063371061273\n",
            "Iteration: 243\t Weight: [9.69085091]\t Bias: [2.50549709]\t Cost: 15.565063370919157\n",
            "Iteration: 244\t Weight: [9.69085085]\t Bias: [2.50549762]\t Cost: 15.565063370777157\n",
            "Iteration: 245\t Weight: [9.69085078]\t Bias: [2.50549815]\t Cost: 15.565063370635265\n",
            "Iteration: 246\t Weight: [9.69085071]\t Bias: [2.50549867]\t Cost: 15.565063370493492\n",
            "Iteration: 247\t Weight: [9.69085064]\t Bias: [2.5054992]\t Cost: 15.56506337035183\n",
            "Iteration: 248\t Weight: [9.69085057]\t Bias: [2.50549973]\t Cost: 15.565063370210284\n",
            "Iteration: 249\t Weight: [9.6908505]\t Bias: [2.50550026]\t Cost: 15.565063370068838\n",
            "Iteration: 250\t Weight: [9.69085042]\t Bias: [2.50550078]\t Cost: 15.565063369927515\n",
            "Iteration: 251\t Weight: [9.69085035]\t Bias: [2.50550131]\t Cost: 15.565063369786284\n",
            "Iteration: 252\t Weight: [9.69085028]\t Bias: [2.50550184]\t Cost: 15.565063369645161\n",
            "Iteration: 253\t Weight: [9.6908502]\t Bias: [2.50550236]\t Cost: 15.565063369504148\n",
            "Iteration: 254\t Weight: [9.69085013]\t Bias: [2.50550289]\t Cost: 15.565063369363244\n",
            "Iteration: 255\t Weight: [9.69085005]\t Bias: [2.50550341]\t Cost: 15.56506336922245\n",
            "Iteration: 256\t Weight: [9.69084998]\t Bias: [2.50550394]\t Cost: 15.56506336908175\n",
            "Iteration: 257\t Weight: [9.6908499]\t Bias: [2.50550446]\t Cost: 15.565063368941148\n",
            "Iteration: 258\t Weight: [9.69084983]\t Bias: [2.50550499]\t Cost: 15.565063368800663\n",
            "Iteration: 259\t Weight: [9.69084975]\t Bias: [2.50550551]\t Cost: 15.565063368660274\n",
            "Iteration: 260\t Weight: [9.69084967]\t Bias: [2.50550604]\t Cost: 15.565063368520004\n",
            "Iteration: 261\t Weight: [9.69084959]\t Bias: [2.50550656]\t Cost: 15.565063368379814\n",
            "Iteration: 262\t Weight: [9.69084952]\t Bias: [2.50550708]\t Cost: 15.565063368239736\n",
            "Iteration: 263\t Weight: [9.69084944]\t Bias: [2.50550761]\t Cost: 15.56506336809976\n",
            "Iteration: 264\t Weight: [9.69084936]\t Bias: [2.50550813]\t Cost: 15.565063367959889\n",
            "Iteration: 265\t Weight: [9.69084928]\t Bias: [2.50550865]\t Cost: 15.565063367820109\n",
            "Iteration: 266\t Weight: [9.69084921]\t Bias: [2.50550918]\t Cost: 15.565063367680443\n",
            "Iteration: 267\t Weight: [9.69084913]\t Bias: [2.5055097]\t Cost: 15.56506336754088\n",
            "Iteration: 268\t Weight: [9.69084905]\t Bias: [2.50551022]\t Cost: 15.565063367401411\n",
            "Iteration: 269\t Weight: [9.69084897]\t Bias: [2.50551074]\t Cost: 15.56506336726203\n",
            "Iteration: 270\t Weight: [9.69084889]\t Bias: [2.50551127]\t Cost: 15.565063367122773\n",
            "Iteration: 271\t Weight: [9.69084881]\t Bias: [2.50551179]\t Cost: 15.565063366983614\n",
            "Iteration: 272\t Weight: [9.69084873]\t Bias: [2.50551231]\t Cost: 15.565063366844544\n",
            "Iteration: 273\t Weight: [9.69084865]\t Bias: [2.50551283]\t Cost: 15.565063366705582\n",
            "Iteration: 274\t Weight: [9.69084857]\t Bias: [2.50551335]\t Cost: 15.56506336656672\n",
            "Iteration: 275\t Weight: [9.69084849]\t Bias: [2.50551387]\t Cost: 15.565063366427951\n",
            "Iteration: 276\t Weight: [9.69084842]\t Bias: [2.50551439]\t Cost: 15.565063366289296\n",
            "Iteration: 277\t Weight: [9.69084834]\t Bias: [2.50551491]\t Cost: 15.56506336615073\n",
            "Iteration: 278\t Weight: [9.69084826]\t Bias: [2.50551543]\t Cost: 15.56506336601227\n",
            "Iteration: 279\t Weight: [9.69084818]\t Bias: [2.50551595]\t Cost: 15.5650633658739\n",
            "Iteration: 280\t Weight: [9.6908481]\t Bias: [2.50551647]\t Cost: 15.565063365735648\n",
            "Iteration: 281\t Weight: [9.69084802]\t Bias: [2.50551699]\t Cost: 15.565063365597478\n",
            "Iteration: 282\t Weight: [9.69084794]\t Bias: [2.50551751]\t Cost: 15.565063365459414\n",
            "Iteration: 283\t Weight: [9.69084786]\t Bias: [2.50551803]\t Cost: 15.565063365321459\n",
            "Iteration: 284\t Weight: [9.69084778]\t Bias: [2.50551855]\t Cost: 15.565063365183597\n",
            "Iteration: 285\t Weight: [9.6908477]\t Bias: [2.50551907]\t Cost: 15.565063365045829\n",
            "Iteration: 286\t Weight: [9.69084762]\t Bias: [2.50551959]\t Cost: 15.565063364908164\n",
            "Iteration: 287\t Weight: [9.69084754]\t Bias: [2.50552011]\t Cost: 15.565063364770605\n",
            "Iteration: 288\t Weight: [9.69084746]\t Bias: [2.50552062]\t Cost: 15.565063364633144\n",
            "Iteration: 289\t Weight: [9.69084738]\t Bias: [2.50552114]\t Cost: 15.565063364495783\n",
            "Iteration: 290\t Weight: [9.6908473]\t Bias: [2.50552166]\t Cost: 15.565063364358503\n",
            "Iteration: 291\t Weight: [9.69084722]\t Bias: [2.50552218]\t Cost: 15.565063364221354\n",
            "Iteration: 292\t Weight: [9.69084714]\t Bias: [2.5055227]\t Cost: 15.565063364084276\n",
            "Iteration: 293\t Weight: [9.69084706]\t Bias: [2.50552321]\t Cost: 15.565063363947298\n",
            "Iteration: 294\t Weight: [9.69084698]\t Bias: [2.50552373]\t Cost: 15.565063363810436\n",
            "Iteration: 295\t Weight: [9.6908469]\t Bias: [2.50552425]\t Cost: 15.565063363673662\n",
            "Iteration: 296\t Weight: [9.69084682]\t Bias: [2.50552476]\t Cost: 15.56506336353699\n",
            "Iteration: 297\t Weight: [9.69084674]\t Bias: [2.50552528]\t Cost: 15.565063363400418\n",
            "Iteration: 298\t Weight: [9.69084666]\t Bias: [2.5055258]\t Cost: 15.565063363263949\n",
            "Iteration: 299\t Weight: [9.69084658]\t Bias: [2.50552631]\t Cost: 15.565063363127573\n",
            "Iteration: 300\t Weight: [9.6908465]\t Bias: [2.50552683]\t Cost: 15.565063362991292\n",
            "Iteration: 301\t Weight: [9.69084642]\t Bias: [2.50552734]\t Cost: 15.565063362855117\n",
            "Iteration: 302\t Weight: [9.69084634]\t Bias: [2.50552786]\t Cost: 15.565063362719032\n",
            "Iteration: 303\t Weight: [9.69084626]\t Bias: [2.50552837]\t Cost: 15.565063362583047\n",
            "Iteration: 304\t Weight: [9.69084618]\t Bias: [2.50552889]\t Cost: 15.565063362447159\n",
            "Iteration: 305\t Weight: [9.6908461]\t Bias: [2.50552941]\t Cost: 15.565063362311374\n",
            "Iteration: 306\t Weight: [9.69084602]\t Bias: [2.50552992]\t Cost: 15.565063362175692\n",
            "Iteration: 307\t Weight: [9.69084594]\t Bias: [2.50553043]\t Cost: 15.565063362040101\n",
            "Iteration: 308\t Weight: [9.69084586]\t Bias: [2.50553095]\t Cost: 15.565063361904604\n",
            "Iteration: 309\t Weight: [9.69084578]\t Bias: [2.50553146]\t Cost: 15.565063361769214\n",
            "Iteration: 310\t Weight: [9.6908457]\t Bias: [2.50553198]\t Cost: 15.565063361633916\n",
            "Iteration: 311\t Weight: [9.69084562]\t Bias: [2.50553249]\t Cost: 15.56506336149871\n",
            "Iteration: 312\t Weight: [9.69084554]\t Bias: [2.50553301]\t Cost: 15.565063361363613\n",
            "Iteration: 313\t Weight: [9.69084546]\t Bias: [2.50553352]\t Cost: 15.565063361228605\n",
            "Iteration: 314\t Weight: [9.69084538]\t Bias: [2.50553403]\t Cost: 15.565063361093696\n",
            "Iteration: 315\t Weight: [9.6908453]\t Bias: [2.50553455]\t Cost: 15.565063360958893\n",
            "Iteration: 316\t Weight: [9.69084522]\t Bias: [2.50553506]\t Cost: 15.56506336082418\n",
            "Iteration: 317\t Weight: [9.69084514]\t Bias: [2.50553557]\t Cost: 15.565063360689573\n",
            "Iteration: 318\t Weight: [9.69084506]\t Bias: [2.50553608]\t Cost: 15.56506336055504\n",
            "Iteration: 319\t Weight: [9.69084498]\t Bias: [2.5055366]\t Cost: 15.565063360420629\n",
            "Iteration: 320\t Weight: [9.6908449]\t Bias: [2.50553711]\t Cost: 15.56506336028632\n",
            "Iteration: 321\t Weight: [9.69084483]\t Bias: [2.50553762]\t Cost: 15.56506336015208\n",
            "Iteration: 322\t Weight: [9.69084475]\t Bias: [2.50553813]\t Cost: 15.56506336001796\n",
            "Iteration: 323\t Weight: [9.69084467]\t Bias: [2.50553864]\t Cost: 15.56506335988393\n",
            "Iteration: 324\t Weight: [9.69084459]\t Bias: [2.50553916]\t Cost: 15.565063359749995\n",
            "Iteration: 325\t Weight: [9.69084451]\t Bias: [2.50553967]\t Cost: 15.56506335961615\n",
            "Iteration: 326\t Weight: [9.69084443]\t Bias: [2.50554018]\t Cost: 15.565063359482414\n",
            "Iteration: 327\t Weight: [9.69084435]\t Bias: [2.50554069]\t Cost: 15.565063359348763\n",
            "Iteration: 328\t Weight: [9.69084427]\t Bias: [2.5055412]\t Cost: 15.565063359215216\n",
            "Iteration: 329\t Weight: [9.69084419]\t Bias: [2.50554171]\t Cost: 15.565063359081762\n",
            "Iteration: 330\t Weight: [9.69084411]\t Bias: [2.50554222]\t Cost: 15.565063358948404\n",
            "Iteration: 331\t Weight: [9.69084403]\t Bias: [2.50554273]\t Cost: 15.56506335881515\n",
            "Iteration: 332\t Weight: [9.69084395]\t Bias: [2.50554324]\t Cost: 15.565063358681975\n",
            "Iteration: 333\t Weight: [9.69084387]\t Bias: [2.50554375]\t Cost: 15.565063358548919\n",
            "Iteration: 334\t Weight: [9.69084379]\t Bias: [2.50554426]\t Cost: 15.565063358415948\n",
            "Iteration: 335\t Weight: [9.69084372]\t Bias: [2.50554477]\t Cost: 15.56506335828307\n",
            "Iteration: 336\t Weight: [9.69084364]\t Bias: [2.50554528]\t Cost: 15.56506335815029\n",
            "Iteration: 337\t Weight: [9.69084356]\t Bias: [2.50554579]\t Cost: 15.565063358017616\n",
            "Iteration: 338\t Weight: [9.69084348]\t Bias: [2.5055463]\t Cost: 15.565063357885013\n",
            "Iteration: 339\t Weight: [9.6908434]\t Bias: [2.50554681]\t Cost: 15.565063357752527\n",
            "Iteration: 340\t Weight: [9.69084332]\t Bias: [2.50554731]\t Cost: 15.56506335762014\n",
            "Iteration: 341\t Weight: [9.69084324]\t Bias: [2.50554782]\t Cost: 15.56506335748784\n",
            "Iteration: 342\t Weight: [9.69084316]\t Bias: [2.50554833]\t Cost: 15.565063357355637\n",
            "Iteration: 343\t Weight: [9.69084308]\t Bias: [2.50554884]\t Cost: 15.565063357223515\n",
            "Iteration: 344\t Weight: [9.690843]\t Bias: [2.50554935]\t Cost: 15.565063357091512\n",
            "Iteration: 345\t Weight: [9.69084293]\t Bias: [2.50554985]\t Cost: 15.565063356959588\n",
            "Iteration: 346\t Weight: [9.69084285]\t Bias: [2.50555036]\t Cost: 15.56506335682777\n",
            "Iteration: 347\t Weight: [9.69084277]\t Bias: [2.50555087]\t Cost: 15.56506335669604\n",
            "Iteration: 348\t Weight: [9.69084269]\t Bias: [2.50555138]\t Cost: 15.565063356564407\n",
            "Iteration: 349\t Weight: [9.69084261]\t Bias: [2.50555188]\t Cost: 15.565063356432871\n",
            "Iteration: 350\t Weight: [9.69084253]\t Bias: [2.50555239]\t Cost: 15.565063356301428\n",
            "Iteration: 351\t Weight: [9.69084245]\t Bias: [2.5055529]\t Cost: 15.565063356170079\n",
            "Iteration: 352\t Weight: [9.69084237]\t Bias: [2.5055534]\t Cost: 15.565063356038829\n",
            "Iteration: 353\t Weight: [9.6908423]\t Bias: [2.50555391]\t Cost: 15.56506335590767\n",
            "Iteration: 354\t Weight: [9.69084222]\t Bias: [2.50555441]\t Cost: 15.5650633557766\n",
            "Iteration: 355\t Weight: [9.69084214]\t Bias: [2.50555492]\t Cost: 15.565063355645643\n",
            "Iteration: 356\t Weight: [9.69084206]\t Bias: [2.50555543]\t Cost: 15.56506335551477\n",
            "Iteration: 357\t Weight: [9.69084198]\t Bias: [2.50555593]\t Cost: 15.565063355383963\n",
            "Iteration: 358\t Weight: [9.6908419]\t Bias: [2.50555644]\t Cost: 15.565063355253296\n",
            "Iteration: 359\t Weight: [9.69084182]\t Bias: [2.50555694]\t Cost: 15.565063355122696\n",
            "Iteration: 360\t Weight: [9.69084175]\t Bias: [2.50555745]\t Cost: 15.565063354992212\n",
            "Iteration: 361\t Weight: [9.69084167]\t Bias: [2.50555795]\t Cost: 15.565063354861813\n",
            "Iteration: 362\t Weight: [9.69084159]\t Bias: [2.50555845]\t Cost: 15.565063354731496\n",
            "Iteration: 363\t Weight: [9.69084151]\t Bias: [2.50555896]\t Cost: 15.56506335460129\n",
            "Iteration: 364\t Weight: [9.69084143]\t Bias: [2.50555946]\t Cost: 15.56506335447117\n",
            "Iteration: 365\t Weight: [9.69084135]\t Bias: [2.50555997]\t Cost: 15.565063354341145\n",
            "Iteration: 366\t Weight: [9.69084128]\t Bias: [2.50556047]\t Cost: 15.565063354211215\n",
            "Iteration: 367\t Weight: [9.6908412]\t Bias: [2.50556097]\t Cost: 15.565063354081376\n",
            "Iteration: 368\t Weight: [9.69084112]\t Bias: [2.50556148]\t Cost: 15.565063353951631\n",
            "Iteration: 369\t Weight: [9.69084104]\t Bias: [2.50556198]\t Cost: 15.565063353821982\n",
            "Iteration: 370\t Weight: [9.69084096]\t Bias: [2.50556248]\t Cost: 15.565063353692423\n",
            "Iteration: 371\t Weight: [9.69084089]\t Bias: [2.50556299]\t Cost: 15.565063353562953\n",
            "Iteration: 372\t Weight: [9.69084081]\t Bias: [2.50556349]\t Cost: 15.565063353433583\n",
            "Iteration: 373\t Weight: [9.69084073]\t Bias: [2.50556399]\t Cost: 15.565063353304309\n",
            "Iteration: 374\t Weight: [9.69084065]\t Bias: [2.50556449]\t Cost: 15.565063353175127\n",
            "Iteration: 375\t Weight: [9.69084057]\t Bias: [2.505565]\t Cost: 15.565063353046039\n",
            "Iteration: 376\t Weight: [9.6908405]\t Bias: [2.5055655]\t Cost: 15.565063352917038\n",
            "Iteration: 377\t Weight: [9.69084042]\t Bias: [2.505566]\t Cost: 15.565063352788131\n",
            "Iteration: 378\t Weight: [9.69084034]\t Bias: [2.5055665]\t Cost: 15.565063352659333\n",
            "Iteration: 379\t Weight: [9.69084026]\t Bias: [2.505567]\t Cost: 15.565063352530602\n",
            "Iteration: 380\t Weight: [9.69084018]\t Bias: [2.5055675]\t Cost: 15.56506335240198\n",
            "Iteration: 381\t Weight: [9.69084011]\t Bias: [2.50556801]\t Cost: 15.56506335227345\n",
            "Iteration: 382\t Weight: [9.69084003]\t Bias: [2.50556851]\t Cost: 15.565063352145017\n",
            "Iteration: 383\t Weight: [9.69083995]\t Bias: [2.50556901]\t Cost: 15.565063352016665\n",
            "Iteration: 384\t Weight: [9.69083987]\t Bias: [2.50556951]\t Cost: 15.565063351888416\n",
            "Iteration: 385\t Weight: [9.6908398]\t Bias: [2.50557001]\t Cost: 15.565063351760264\n",
            "Iteration: 386\t Weight: [9.69083972]\t Bias: [2.50557051]\t Cost: 15.56506335163219\n",
            "Iteration: 387\t Weight: [9.69083964]\t Bias: [2.50557101]\t Cost: 15.56506335150422\n",
            "Iteration: 388\t Weight: [9.69083956]\t Bias: [2.50557151]\t Cost: 15.565063351376331\n",
            "Iteration: 389\t Weight: [9.69083948]\t Bias: [2.50557201]\t Cost: 15.56506335124854\n",
            "Iteration: 390\t Weight: [9.69083941]\t Bias: [2.50557251]\t Cost: 15.565063351120846\n",
            "Iteration: 391\t Weight: [9.69083933]\t Bias: [2.50557301]\t Cost: 15.565063350993235\n",
            "Iteration: 392\t Weight: [9.69083925]\t Bias: [2.50557351]\t Cost: 15.56506335086572\n",
            "Iteration: 393\t Weight: [9.69083917]\t Bias: [2.505574]\t Cost: 15.565063350738297\n",
            "Iteration: 394\t Weight: [9.6908391]\t Bias: [2.5055745]\t Cost: 15.565063350610973\n",
            "Iteration: 395\t Weight: [9.69083902]\t Bias: [2.505575]\t Cost: 15.565063350483724\n",
            "Iteration: 396\t Weight: [9.69083894]\t Bias: [2.5055755]\t Cost: 15.565063350356589\n",
            "Iteration: 397\t Weight: [9.69083886]\t Bias: [2.505576]\t Cost: 15.56506335022953\n",
            "Iteration: 398\t Weight: [9.69083879]\t Bias: [2.5055765]\t Cost: 15.565063350102564\n",
            "Iteration: 399\t Weight: [9.69083871]\t Bias: [2.50557699]\t Cost: 15.5650633499757\n",
            "Iteration: 400\t Weight: [9.69083863]\t Bias: [2.50557749]\t Cost: 15.565063349848918\n",
            "Iteration: 401\t Weight: [9.69083856]\t Bias: [2.50557799]\t Cost: 15.565063349722232\n",
            "Iteration: 402\t Weight: [9.69083848]\t Bias: [2.50557849]\t Cost: 15.56506334959564\n",
            "Iteration: 403\t Weight: [9.6908384]\t Bias: [2.50557898]\t Cost: 15.565063349469133\n",
            "Iteration: 404\t Weight: [9.69083832]\t Bias: [2.50557948]\t Cost: 15.565063349342724\n",
            "Iteration: 405\t Weight: [9.69083825]\t Bias: [2.50557998]\t Cost: 15.5650633492164\n",
            "Iteration: 406\t Weight: [9.69083817]\t Bias: [2.50558047]\t Cost: 15.565063349090162\n",
            "Iteration: 407\t Weight: [9.69083809]\t Bias: [2.50558097]\t Cost: 15.565063348964022\n",
            "Iteration: 408\t Weight: [9.69083802]\t Bias: [2.50558147]\t Cost: 15.565063348837977\n",
            "Iteration: 409\t Weight: [9.69083794]\t Bias: [2.50558196]\t Cost: 15.565063348712021\n",
            "Iteration: 410\t Weight: [9.69083786]\t Bias: [2.50558246]\t Cost: 15.565063348586152\n",
            "Iteration: 411\t Weight: [9.69083778]\t Bias: [2.50558295]\t Cost: 15.565063348460384\n",
            "Iteration: 412\t Weight: [9.69083771]\t Bias: [2.50558345]\t Cost: 15.565063348334691\n",
            "Iteration: 413\t Weight: [9.69083763]\t Bias: [2.50558394]\t Cost: 15.565063348209096\n",
            "Iteration: 414\t Weight: [9.69083755]\t Bias: [2.50558444]\t Cost: 15.565063348083598\n",
            "Iteration: 415\t Weight: [9.69083748]\t Bias: [2.50558493]\t Cost: 15.565063347958183\n",
            "Iteration: 416\t Weight: [9.6908374]\t Bias: [2.50558543]\t Cost: 15.565063347832863\n",
            "Iteration: 417\t Weight: [9.69083732]\t Bias: [2.50558592]\t Cost: 15.56506334770764\n",
            "Iteration: 418\t Weight: [9.69083725]\t Bias: [2.50558642]\t Cost: 15.56506334758249\n",
            "Iteration: 419\t Weight: [9.69083717]\t Bias: [2.50558691]\t Cost: 15.565063347457437\n",
            "Iteration: 420\t Weight: [9.69083709]\t Bias: [2.50558741]\t Cost: 15.565063347332483\n",
            "Iteration: 421\t Weight: [9.69083702]\t Bias: [2.5055879]\t Cost: 15.565063347207621\n",
            "Iteration: 422\t Weight: [9.69083694]\t Bias: [2.50558839]\t Cost: 15.565063347082827\n",
            "Iteration: 423\t Weight: [9.69083686]\t Bias: [2.50558889]\t Cost: 15.56506334695815\n",
            "Iteration: 424\t Weight: [9.69083679]\t Bias: [2.50558938]\t Cost: 15.565063346833542\n",
            "Iteration: 425\t Weight: [9.69083671]\t Bias: [2.50558987]\t Cost: 15.565063346709035\n",
            "Iteration: 426\t Weight: [9.69083663]\t Bias: [2.50559037]\t Cost: 15.56506334658461\n",
            "Iteration: 427\t Weight: [9.69083656]\t Bias: [2.50559086]\t Cost: 15.565063346460285\n",
            "Iteration: 428\t Weight: [9.69083648]\t Bias: [2.50559135]\t Cost: 15.565063346336046\n",
            "Iteration: 429\t Weight: [9.6908364]\t Bias: [2.50559184]\t Cost: 15.565063346211891\n",
            "Iteration: 430\t Weight: [9.69083633]\t Bias: [2.50559234]\t Cost: 15.565063346087829\n",
            "Iteration: 431\t Weight: [9.69083625]\t Bias: [2.50559283]\t Cost: 15.56506334596386\n",
            "Iteration: 432\t Weight: [9.69083617]\t Bias: [2.50559332]\t Cost: 15.565063345839981\n",
            "Iteration: 433\t Weight: [9.6908361]\t Bias: [2.50559381]\t Cost: 15.565063345716194\n",
            "Iteration: 434\t Weight: [9.69083602]\t Bias: [2.5055943]\t Cost: 15.565063345592492\n",
            "Iteration: 435\t Weight: [9.69083594]\t Bias: [2.5055948]\t Cost: 15.565063345468873\n",
            "Iteration: 436\t Weight: [9.69083587]\t Bias: [2.50559529]\t Cost: 15.565063345345354\n",
            "Iteration: 437\t Weight: [9.69083579]\t Bias: [2.50559578]\t Cost: 15.565063345221912\n",
            "Iteration: 438\t Weight: [9.69083572]\t Bias: [2.50559627]\t Cost: 15.565063345098569\n",
            "Iteration: 439\t Weight: [9.69083564]\t Bias: [2.50559676]\t Cost: 15.565063344975313\n",
            "Iteration: 440\t Weight: [9.69083556]\t Bias: [2.50559725]\t Cost: 15.565063344852136\n",
            "Iteration: 441\t Weight: [9.69083549]\t Bias: [2.50559774]\t Cost: 15.565063344729062\n",
            "Iteration: 442\t Weight: [9.69083541]\t Bias: [2.50559823]\t Cost: 15.565063344606067\n",
            "Iteration: 443\t Weight: [9.69083533]\t Bias: [2.50559872]\t Cost: 15.565063344483175\n",
            "Iteration: 444\t Weight: [9.69083526]\t Bias: [2.50559921]\t Cost: 15.565063344360361\n",
            "Iteration: 445\t Weight: [9.69083518]\t Bias: [2.5055997]\t Cost: 15.565063344237641\n",
            "Iteration: 446\t Weight: [9.69083511]\t Bias: [2.50560019]\t Cost: 15.565063344115007\n",
            "Iteration: 447\t Weight: [9.69083503]\t Bias: [2.50560068]\t Cost: 15.565063343992461\n",
            "Iteration: 448\t Weight: [9.69083495]\t Bias: [2.50560117]\t Cost: 15.565063343869987\n",
            "Iteration: 449\t Weight: [9.69083488]\t Bias: [2.50560166]\t Cost: 15.565063343747632\n",
            "Iteration: 450\t Weight: [9.6908348]\t Bias: [2.50560214]\t Cost: 15.56506334362535\n",
            "Iteration: 451\t Weight: [9.69083473]\t Bias: [2.50560263]\t Cost: 15.565063343503162\n",
            "Iteration: 452\t Weight: [9.69083465]\t Bias: [2.50560312]\t Cost: 15.565063343381047\n",
            "Iteration: 453\t Weight: [9.69083458]\t Bias: [2.50560361]\t Cost: 15.56506334325904\n",
            "Iteration: 454\t Weight: [9.6908345]\t Bias: [2.5056041]\t Cost: 15.56506334313711\n",
            "Iteration: 455\t Weight: [9.69083442]\t Bias: [2.50560459]\t Cost: 15.565063343015268\n",
            "Iteration: 456\t Weight: [9.69083435]\t Bias: [2.50560507]\t Cost: 15.565063342893515\n",
            "Iteration: 457\t Weight: [9.69083427]\t Bias: [2.50560556]\t Cost: 15.565063342771847\n",
            "Iteration: 458\t Weight: [9.6908342]\t Bias: [2.50560605]\t Cost: 15.565063342650278\n",
            "Iteration: 459\t Weight: [9.69083412]\t Bias: [2.50560654]\t Cost: 15.56506334252879\n",
            "Iteration: 460\t Weight: [9.69083405]\t Bias: [2.50560702]\t Cost: 15.565063342407383\n",
            "Iteration: 461\t Weight: [9.69083397]\t Bias: [2.50560751]\t Cost: 15.565063342286079\n",
            "Iteration: 462\t Weight: [9.69083389]\t Bias: [2.505608]\t Cost: 15.565063342164848\n",
            "Iteration: 463\t Weight: [9.69083382]\t Bias: [2.50560848]\t Cost: 15.565063342043707\n",
            "Iteration: 464\t Weight: [9.69083374]\t Bias: [2.50560897]\t Cost: 15.565063341922665\n",
            "Iteration: 465\t Weight: [9.69083367]\t Bias: [2.50560945]\t Cost: 15.565063341801702\n",
            "Iteration: 466\t Weight: [9.69083359]\t Bias: [2.50560994]\t Cost: 15.565063341680826\n",
            "Iteration: 467\t Weight: [9.69083352]\t Bias: [2.50561043]\t Cost: 15.56506334156004\n",
            "Iteration: 468\t Weight: [9.69083344]\t Bias: [2.50561091]\t Cost: 15.565063341439332\n",
            "Iteration: 469\t Weight: [9.69083337]\t Bias: [2.5056114]\t Cost: 15.56506334131872\n",
            "Iteration: 470\t Weight: [9.69083329]\t Bias: [2.50561188]\t Cost: 15.565063341198194\n",
            "Iteration: 471\t Weight: [9.69083322]\t Bias: [2.50561237]\t Cost: 15.565063341077753\n",
            "Iteration: 472\t Weight: [9.69083314]\t Bias: [2.50561285]\t Cost: 15.565063340957387\n",
            "Iteration: 473\t Weight: [9.69083306]\t Bias: [2.50561334]\t Cost: 15.565063340837135\n",
            "Iteration: 474\t Weight: [9.69083299]\t Bias: [2.50561382]\t Cost: 15.565063340716954\n",
            "Iteration: 475\t Weight: [9.69083291]\t Bias: [2.50561431]\t Cost: 15.565063340596865\n",
            "Iteration: 476\t Weight: [9.69083284]\t Bias: [2.50561479]\t Cost: 15.565063340476852\n",
            "Iteration: 477\t Weight: [9.69083276]\t Bias: [2.50561527]\t Cost: 15.56506334035694\n",
            "Iteration: 478\t Weight: [9.69083269]\t Bias: [2.50561576]\t Cost: 15.565063340237106\n",
            "Iteration: 479\t Weight: [9.69083261]\t Bias: [2.50561624]\t Cost: 15.565063340117362\n",
            "Iteration: 480\t Weight: [9.69083254]\t Bias: [2.50561672]\t Cost: 15.565063339997701\n",
            "Iteration: 481\t Weight: [9.69083246]\t Bias: [2.50561721]\t Cost: 15.565063339878117\n",
            "Iteration: 482\t Weight: [9.69083239]\t Bias: [2.50561769]\t Cost: 15.565063339758652\n",
            "Iteration: 483\t Weight: [9.69083231]\t Bias: [2.50561817]\t Cost: 15.56506333963924\n",
            "Iteration: 484\t Weight: [9.69083224]\t Bias: [2.50561866]\t Cost: 15.565063339519938\n",
            "Iteration: 485\t Weight: [9.69083216]\t Bias: [2.50561914]\t Cost: 15.5650633394007\n",
            "Iteration: 486\t Weight: [9.69083209]\t Bias: [2.50561962]\t Cost: 15.56506333928156\n",
            "Iteration: 487\t Weight: [9.69083201]\t Bias: [2.5056201]\t Cost: 15.56506333916251\n",
            "Iteration: 488\t Weight: [9.69083194]\t Bias: [2.50562059]\t Cost: 15.565063339043537\n",
            "Iteration: 489\t Weight: [9.69083186]\t Bias: [2.50562107]\t Cost: 15.565063338924656\n",
            "Iteration: 490\t Weight: [9.69083179]\t Bias: [2.50562155]\t Cost: 15.565063338805857\n",
            "Iteration: 491\t Weight: [9.69083171]\t Bias: [2.50562203]\t Cost: 15.565063338687153\n",
            "Iteration: 492\t Weight: [9.69083164]\t Bias: [2.50562251]\t Cost: 15.565063338568525\n",
            "Iteration: 493\t Weight: [9.69083156]\t Bias: [2.50562299]\t Cost: 15.565063338449985\n",
            "Iteration: 494\t Weight: [9.69083149]\t Bias: [2.50562347]\t Cost: 15.565063338331521\n",
            "Iteration: 495\t Weight: [9.69083141]\t Bias: [2.50562396]\t Cost: 15.56506333821315\n",
            "Iteration: 496\t Weight: [9.69083134]\t Bias: [2.50562444]\t Cost: 15.565063338094879\n",
            "Iteration: 497\t Weight: [9.69083127]\t Bias: [2.50562492]\t Cost: 15.565063337976673\n",
            "Iteration: 498\t Weight: [9.69083119]\t Bias: [2.5056254]\t Cost: 15.565063337858549\n",
            "Iteration: 499\t Weight: [9.69083112]\t Bias: [2.50562588]\t Cost: 15.56506333774053\n",
            "Iteration: 500\t Weight: [9.69083104]\t Bias: [2.50562636]\t Cost: 15.565063337622586\n",
            "Iteration: 501\t Weight: [9.69083097]\t Bias: [2.50562684]\t Cost: 15.565063337504732\n",
            "Iteration: 502\t Weight: [9.69083089]\t Bias: [2.50562732]\t Cost: 15.56506333738696\n",
            "Iteration: 503\t Weight: [9.69083082]\t Bias: [2.5056278]\t Cost: 15.565063337269278\n",
            "Iteration: 504\t Weight: [9.69083074]\t Bias: [2.50562828]\t Cost: 15.565063337151667\n",
            "Iteration: 505\t Weight: [9.69083067]\t Bias: [2.50562875]\t Cost: 15.56506333703415\n",
            "Iteration: 506\t Weight: [9.6908306]\t Bias: [2.50562923]\t Cost: 15.565063336916712\n",
            "Iteration: 507\t Weight: [9.69083052]\t Bias: [2.50562971]\t Cost: 15.565063336799373\n",
            "Iteration: 508\t Weight: [9.69083045]\t Bias: [2.50563019]\t Cost: 15.565063336682117\n",
            "Iteration: 509\t Weight: [9.69083037]\t Bias: [2.50563067]\t Cost: 15.565063336564938\n",
            "Iteration: 510\t Weight: [9.6908303]\t Bias: [2.50563115]\t Cost: 15.56506333644784\n",
            "Iteration: 511\t Weight: [9.69083022]\t Bias: [2.50563163]\t Cost: 15.565063336330837\n",
            "Iteration: 512\t Weight: [9.69083015]\t Bias: [2.5056321]\t Cost: 15.565063336213903\n",
            "Iteration: 513\t Weight: [9.69083008]\t Bias: [2.50563258]\t Cost: 15.56506333609707\n",
            "Iteration: 514\t Weight: [9.69083]\t Bias: [2.50563306]\t Cost: 15.565063335980305\n",
            "Iteration: 515\t Weight: [9.69082993]\t Bias: [2.50563354]\t Cost: 15.565063335863641\n",
            "Iteration: 516\t Weight: [9.69082985]\t Bias: [2.50563401]\t Cost: 15.565063335747054\n",
            "Iteration: 517\t Weight: [9.69082978]\t Bias: [2.50563449]\t Cost: 15.565063335630557\n",
            "Iteration: 518\t Weight: [9.6908297]\t Bias: [2.50563497]\t Cost: 15.565063335514136\n",
            "Iteration: 519\t Weight: [9.69082963]\t Bias: [2.50563544]\t Cost: 15.565063335397802\n",
            "Iteration: 520\t Weight: [9.69082956]\t Bias: [2.50563592]\t Cost: 15.565063335281545\n",
            "Iteration: 521\t Weight: [9.69082948]\t Bias: [2.5056364]\t Cost: 15.565063335165377\n",
            "Iteration: 522\t Weight: [9.69082941]\t Bias: [2.50563687]\t Cost: 15.565063335049304\n",
            "Iteration: 523\t Weight: [9.69082933]\t Bias: [2.50563735]\t Cost: 15.565063334933305\n",
            "Iteration: 524\t Weight: [9.69082926]\t Bias: [2.50563782]\t Cost: 15.56506333481738\n",
            "Iteration: 525\t Weight: [9.69082919]\t Bias: [2.5056383]\t Cost: 15.565063334701552\n",
            "Iteration: 526\t Weight: [9.69082911]\t Bias: [2.50563878]\t Cost: 15.565063334585798\n",
            "Iteration: 527\t Weight: [9.69082904]\t Bias: [2.50563925]\t Cost: 15.565063334470135\n",
            "Iteration: 528\t Weight: [9.69082897]\t Bias: [2.50563973]\t Cost: 15.565063334354562\n",
            "Iteration: 529\t Weight: [9.69082889]\t Bias: [2.5056402]\t Cost: 15.56506333423907\n",
            "Iteration: 530\t Weight: [9.69082882]\t Bias: [2.50564068]\t Cost: 15.565063334123655\n",
            "Iteration: 531\t Weight: [9.69082874]\t Bias: [2.50564115]\t Cost: 15.565063334008329\n",
            "Iteration: 532\t Weight: [9.69082867]\t Bias: [2.50564162]\t Cost: 15.565063333893088\n",
            "Iteration: 533\t Weight: [9.6908286]\t Bias: [2.5056421]\t Cost: 15.56506333377792\n",
            "Iteration: 534\t Weight: [9.69082852]\t Bias: [2.50564257]\t Cost: 15.565063333662831\n",
            "Iteration: 535\t Weight: [9.69082845]\t Bias: [2.50564305]\t Cost: 15.565063333547833\n",
            "Iteration: 536\t Weight: [9.69082838]\t Bias: [2.50564352]\t Cost: 15.565063333432917\n",
            "Iteration: 537\t Weight: [9.6908283]\t Bias: [2.50564399]\t Cost: 15.565063333318099\n",
            "Iteration: 538\t Weight: [9.69082823]\t Bias: [2.50564447]\t Cost: 15.565063333203344\n",
            "Iteration: 539\t Weight: [9.69082816]\t Bias: [2.50564494]\t Cost: 15.565063333088673\n",
            "Iteration: 540\t Weight: [9.69082808]\t Bias: [2.50564541]\t Cost: 15.565063332974097\n",
            "Iteration: 541\t Weight: [9.69082801]\t Bias: [2.50564589]\t Cost: 15.56506333285959\n",
            "Iteration: 542\t Weight: [9.69082793]\t Bias: [2.50564636]\t Cost: 15.565063332745183\n",
            "Iteration: 543\t Weight: [9.69082786]\t Bias: [2.50564683]\t Cost: 15.565063332630842\n",
            "Iteration: 544\t Weight: [9.69082779]\t Bias: [2.5056473]\t Cost: 15.565063332516596\n",
            "Iteration: 545\t Weight: [9.69082771]\t Bias: [2.50564778]\t Cost: 15.565063332402417\n",
            "Iteration: 546\t Weight: [9.69082764]\t Bias: [2.50564825]\t Cost: 15.565063332288325\n",
            "Iteration: 547\t Weight: [9.69082757]\t Bias: [2.50564872]\t Cost: 15.56506333217432\n",
            "Iteration: 548\t Weight: [9.69082749]\t Bias: [2.50564919]\t Cost: 15.565063332060408\n",
            "Iteration: 549\t Weight: [9.69082742]\t Bias: [2.50564966]\t Cost: 15.565063331946563\n",
            "Iteration: 550\t Weight: [9.69082735]\t Bias: [2.50565014]\t Cost: 15.565063331832803\n",
            "Iteration: 551\t Weight: [9.69082727]\t Bias: [2.50565061]\t Cost: 15.56506333171912\n",
            "Iteration: 552\t Weight: [9.6908272]\t Bias: [2.50565108]\t Cost: 15.56506333160554\n",
            "Iteration: 553\t Weight: [9.69082713]\t Bias: [2.50565155]\t Cost: 15.565063331492023\n",
            "Iteration: 554\t Weight: [9.69082706]\t Bias: [2.50565202]\t Cost: 15.565063331378612\n",
            "Iteration: 555\t Weight: [9.69082698]\t Bias: [2.50565249]\t Cost: 15.565063331265256\n",
            "Iteration: 556\t Weight: [9.69082691]\t Bias: [2.50565296]\t Cost: 15.565063331151988\n",
            "Iteration: 557\t Weight: [9.69082684]\t Bias: [2.50565343]\t Cost: 15.565063331038798\n",
            "Iteration: 558\t Weight: [9.69082676]\t Bias: [2.5056539]\t Cost: 15.565063330925705\n",
            "Iteration: 559\t Weight: [9.69082669]\t Bias: [2.50565437]\t Cost: 15.565063330812674\n",
            "Iteration: 560\t Weight: [9.69082662]\t Bias: [2.50565484]\t Cost: 15.565063330699745\n",
            "Iteration: 561\t Weight: [9.69082654]\t Bias: [2.50565531]\t Cost: 15.565063330586883\n",
            "Iteration: 562\t Weight: [9.69082647]\t Bias: [2.50565578]\t Cost: 15.565063330474109\n",
            "Iteration: 563\t Weight: [9.6908264]\t Bias: [2.50565625]\t Cost: 15.565063330361415\n",
            "Iteration: 564\t Weight: [9.69082633]\t Bias: [2.50565672]\t Cost: 15.565063330248794\n",
            "Iteration: 565\t Weight: [9.69082625]\t Bias: [2.50565719]\t Cost: 15.565063330136267\n",
            "Iteration: 566\t Weight: [9.69082618]\t Bias: [2.50565765]\t Cost: 15.56506333002381\n",
            "Iteration: 567\t Weight: [9.69082611]\t Bias: [2.50565812]\t Cost: 15.565063329911453\n",
            "Iteration: 568\t Weight: [9.69082603]\t Bias: [2.50565859]\t Cost: 15.565063329799166\n",
            "Iteration: 569\t Weight: [9.69082596]\t Bias: [2.50565906]\t Cost: 15.565063329686955\n",
            "Iteration: 570\t Weight: [9.69082589]\t Bias: [2.50565953]\t Cost: 15.565063329574825\n",
            "Iteration: 571\t Weight: [9.69082582]\t Bias: [2.50566]\t Cost: 15.565063329462786\n",
            "Iteration: 572\t Weight: [9.69082574]\t Bias: [2.50566046]\t Cost: 15.565063329350812\n",
            "Iteration: 573\t Weight: [9.69082567]\t Bias: [2.50566093]\t Cost: 15.565063329238939\n",
            "Iteration: 574\t Weight: [9.6908256]\t Bias: [2.5056614]\t Cost: 15.565063329127131\n",
            "Iteration: 575\t Weight: [9.69082553]\t Bias: [2.50566186]\t Cost: 15.565063329015416\n",
            "Iteration: 576\t Weight: [9.69082545]\t Bias: [2.50566233]\t Cost: 15.56506332890377\n",
            "Iteration: 577\t Weight: [9.69082538]\t Bias: [2.5056628]\t Cost: 15.565063328792208\n",
            "Iteration: 578\t Weight: [9.69082531]\t Bias: [2.50566327]\t Cost: 15.565063328680742\n",
            "Iteration: 579\t Weight: [9.69082524]\t Bias: [2.50566373]\t Cost: 15.56506332856933\n",
            "Iteration: 580\t Weight: [9.69082516]\t Bias: [2.5056642]\t Cost: 15.565063328458015\n",
            "Iteration: 581\t Weight: [9.69082509]\t Bias: [2.50566466]\t Cost: 15.565063328346772\n",
            "Iteration: 582\t Weight: [9.69082502]\t Bias: [2.50566513]\t Cost: 15.565063328235627\n",
            "Iteration: 583\t Weight: [9.69082495]\t Bias: [2.5056656]\t Cost: 15.565063328124527\n",
            "Iteration: 584\t Weight: [9.69082487]\t Bias: [2.50566606]\t Cost: 15.565063328013547\n",
            "Iteration: 585\t Weight: [9.6908248]\t Bias: [2.50566653]\t Cost: 15.565063327902626\n",
            "Iteration: 586\t Weight: [9.69082473]\t Bias: [2.50566699]\t Cost: 15.565063327791789\n",
            "Iteration: 587\t Weight: [9.69082466]\t Bias: [2.50566746]\t Cost: 15.565063327681038\n",
            "Iteration: 588\t Weight: [9.69082459]\t Bias: [2.50566792]\t Cost: 15.565063327570348\n",
            "Iteration: 589\t Weight: [9.69082451]\t Bias: [2.50566839]\t Cost: 15.565063327459756\n",
            "Iteration: 590\t Weight: [9.69082444]\t Bias: [2.50566885]\t Cost: 15.565063327349243\n",
            "Iteration: 591\t Weight: [9.69082437]\t Bias: [2.50566932]\t Cost: 15.565063327238809\n",
            "Iteration: 592\t Weight: [9.6908243]\t Bias: [2.50566978]\t Cost: 15.565063327128442\n",
            "Iteration: 593\t Weight: [9.69082422]\t Bias: [2.50567024]\t Cost: 15.565063327018168\n",
            "Iteration: 594\t Weight: [9.69082415]\t Bias: [2.50567071]\t Cost: 15.565063326907968\n",
            "Iteration: 595\t Weight: [9.69082408]\t Bias: [2.50567117]\t Cost: 15.565063326797853\n",
            "Iteration: 596\t Weight: [9.69082401]\t Bias: [2.50567164]\t Cost: 15.56506332668781\n",
            "Iteration: 597\t Weight: [9.69082394]\t Bias: [2.5056721]\t Cost: 15.565063326577853\n",
            "Iteration: 598\t Weight: [9.69082386]\t Bias: [2.50567256]\t Cost: 15.565063326467978\n",
            "Iteration: 599\t Weight: [9.69082379]\t Bias: [2.50567303]\t Cost: 15.565063326358175\n",
            "Iteration: 600\t Weight: [9.69082372]\t Bias: [2.50567349]\t Cost: 15.565063326248445\n",
            "Iteration: 601\t Weight: [9.69082365]\t Bias: [2.50567395]\t Cost: 15.565063326138796\n",
            "Iteration: 602\t Weight: [9.69082358]\t Bias: [2.50567441]\t Cost: 15.56506332602924\n",
            "Iteration: 603\t Weight: [9.69082351]\t Bias: [2.50567488]\t Cost: 15.565063325919755\n",
            "Iteration: 604\t Weight: [9.69082343]\t Bias: [2.50567534]\t Cost: 15.565063325810351\n",
            "Iteration: 605\t Weight: [9.69082336]\t Bias: [2.5056758]\t Cost: 15.565063325701036\n",
            "Iteration: 606\t Weight: [9.69082329]\t Bias: [2.50567626]\t Cost: 15.56506332559178\n",
            "Iteration: 607\t Weight: [9.69082322]\t Bias: [2.50567672]\t Cost: 15.56506332548261\n",
            "Iteration: 608\t Weight: [9.69082315]\t Bias: [2.50567719]\t Cost: 15.565063325373515\n",
            "Iteration: 609\t Weight: [9.69082307]\t Bias: [2.50567765]\t Cost: 15.565063325264518\n",
            "Iteration: 610\t Weight: [9.690823]\t Bias: [2.50567811]\t Cost: 15.565063325155574\n",
            "Iteration: 611\t Weight: [9.69082293]\t Bias: [2.50567857]\t Cost: 15.56506332504673\n",
            "Iteration: 612\t Weight: [9.69082286]\t Bias: [2.50567903]\t Cost: 15.565063324937952\n",
            "Iteration: 613\t Weight: [9.69082279]\t Bias: [2.50567949]\t Cost: 15.565063324829255\n",
            "Iteration: 614\t Weight: [9.69082272]\t Bias: [2.50567995]\t Cost: 15.565063324720642\n",
            "Iteration: 615\t Weight: [9.69082265]\t Bias: [2.50568041]\t Cost: 15.56506332461209\n",
            "Iteration: 616\t Weight: [9.69082257]\t Bias: [2.50568087]\t Cost: 15.56506332450364\n",
            "Iteration: 617\t Weight: [9.6908225]\t Bias: [2.50568133]\t Cost: 15.56506332439525\n",
            "Iteration: 618\t Weight: [9.69082243]\t Bias: [2.50568179]\t Cost: 15.565063324286958\n",
            "Iteration: 619\t Weight: [9.69082236]\t Bias: [2.50568225]\t Cost: 15.565063324178729\n",
            "Iteration: 620\t Weight: [9.69082229]\t Bias: [2.50568271]\t Cost: 15.565063324070577\n",
            "Iteration: 621\t Weight: [9.69082222]\t Bias: [2.50568317]\t Cost: 15.565063323962514\n",
            "Iteration: 622\t Weight: [9.69082215]\t Bias: [2.50568363]\t Cost: 15.565063323854519\n",
            "Iteration: 623\t Weight: [9.69082207]\t Bias: [2.50568409]\t Cost: 15.565063323746596\n",
            "Iteration: 624\t Weight: [9.690822]\t Bias: [2.50568455]\t Cost: 15.565063323638771\n",
            "Iteration: 625\t Weight: [9.69082193]\t Bias: [2.50568501]\t Cost: 15.565063323531014\n",
            "Iteration: 626\t Weight: [9.69082186]\t Bias: [2.50568547]\t Cost: 15.565063323423319\n",
            "Iteration: 627\t Weight: [9.69082179]\t Bias: [2.50568592]\t Cost: 15.56506332331573\n",
            "Iteration: 628\t Weight: [9.69082172]\t Bias: [2.50568638]\t Cost: 15.565063323208207\n",
            "Iteration: 629\t Weight: [9.69082165]\t Bias: [2.50568684]\t Cost: 15.565063323100748\n",
            "Iteration: 630\t Weight: [9.69082158]\t Bias: [2.5056873]\t Cost: 15.565063322993378\n",
            "Iteration: 631\t Weight: [9.6908215]\t Bias: [2.50568776]\t Cost: 15.5650633228861\n",
            "Iteration: 632\t Weight: [9.69082143]\t Bias: [2.50568821]\t Cost: 15.56506332277889\n",
            "Iteration: 633\t Weight: [9.69082136]\t Bias: [2.50568867]\t Cost: 15.565063322671747\n",
            "Iteration: 634\t Weight: [9.69082129]\t Bias: [2.50568913]\t Cost: 15.565063322564693\n",
            "Iteration: 635\t Weight: [9.69082122]\t Bias: [2.50568959]\t Cost: 15.56506332245771\n",
            "Iteration: 636\t Weight: [9.69082115]\t Bias: [2.50569004]\t Cost: 15.565063322350802\n",
            "Iteration: 637\t Weight: [9.69082108]\t Bias: [2.5056905]\t Cost: 15.56506332224397\n",
            "Iteration: 638\t Weight: [9.69082101]\t Bias: [2.50569096]\t Cost: 15.565063322137231\n",
            "Iteration: 639\t Weight: [9.69082094]\t Bias: [2.50569141]\t Cost: 15.565063322030548\n",
            "Iteration: 640\t Weight: [9.69082087]\t Bias: [2.50569187]\t Cost: 15.565063321923962\n",
            "Iteration: 641\t Weight: [9.69082079]\t Bias: [2.50569233]\t Cost: 15.565063321817439\n",
            "Iteration: 642\t Weight: [9.69082072]\t Bias: [2.50569278]\t Cost: 15.565063321710994\n",
            "Iteration: 643\t Weight: [9.69082065]\t Bias: [2.50569324]\t Cost: 15.565063321604628\n",
            "Iteration: 644\t Weight: [9.69082058]\t Bias: [2.50569369]\t Cost: 15.565063321498341\n",
            "Iteration: 645\t Weight: [9.69082051]\t Bias: [2.50569415]\t Cost: 15.565063321392131\n",
            "Iteration: 646\t Weight: [9.69082044]\t Bias: [2.5056946]\t Cost: 15.56506332128599\n",
            "Iteration: 647\t Weight: [9.69082037]\t Bias: [2.50569506]\t Cost: 15.565063321179933\n",
            "Iteration: 648\t Weight: [9.6908203]\t Bias: [2.50569551]\t Cost: 15.56506332107395\n",
            "Iteration: 649\t Weight: [9.69082023]\t Bias: [2.50569597]\t Cost: 15.565063320968052\n",
            "Iteration: 650\t Weight: [9.69082016]\t Bias: [2.50569642]\t Cost: 15.565063320862219\n",
            "Iteration: 651\t Weight: [9.69082009]\t Bias: [2.50569688]\t Cost: 15.565063320756472\n",
            "Iteration: 652\t Weight: [9.69082002]\t Bias: [2.50569733]\t Cost: 15.565063320650788\n",
            "Iteration: 653\t Weight: [9.69081995]\t Bias: [2.50569779]\t Cost: 15.565063320545187\n",
            "Iteration: 654\t Weight: [9.69081988]\t Bias: [2.50569824]\t Cost: 15.565063320439673\n",
            "Iteration: 655\t Weight: [9.69081981]\t Bias: [2.50569869]\t Cost: 15.565063320334215\n",
            "Iteration: 656\t Weight: [9.69081973]\t Bias: [2.50569915]\t Cost: 15.56506332022885\n",
            "Iteration: 657\t Weight: [9.69081966]\t Bias: [2.5056996]\t Cost: 15.565063320123555\n",
            "Iteration: 658\t Weight: [9.69081959]\t Bias: [2.50570005]\t Cost: 15.56506332001834\n",
            "Iteration: 659\t Weight: [9.69081952]\t Bias: [2.50570051]\t Cost: 15.565063319913202\n",
            "Iteration: 660\t Weight: [9.69081945]\t Bias: [2.50570096]\t Cost: 15.565063319808129\n",
            "Iteration: 661\t Weight: [9.69081938]\t Bias: [2.50570141]\t Cost: 15.565063319703135\n",
            "Iteration: 662\t Weight: [9.69081931]\t Bias: [2.50570187]\t Cost: 15.56506331959822\n",
            "Iteration: 663\t Weight: [9.69081924]\t Bias: [2.50570232]\t Cost: 15.565063319493387\n",
            "Iteration: 664\t Weight: [9.69081917]\t Bias: [2.50570277]\t Cost: 15.565063319388608\n",
            "Iteration: 665\t Weight: [9.6908191]\t Bias: [2.50570322]\t Cost: 15.56506331928392\n",
            "Iteration: 666\t Weight: [9.69081903]\t Bias: [2.50570368]\t Cost: 15.565063319179318\n",
            "Iteration: 667\t Weight: [9.69081896]\t Bias: [2.50570413]\t Cost: 15.565063319074774\n",
            "Iteration: 668\t Weight: [9.69081889]\t Bias: [2.50570458]\t Cost: 15.565063318970322\n",
            "Iteration: 669\t Weight: [9.69081882]\t Bias: [2.50570503]\t Cost: 15.565063318865926\n",
            "Iteration: 670\t Weight: [9.69081875]\t Bias: [2.50570548]\t Cost: 15.565063318761624\n",
            "Iteration: 671\t Weight: [9.69081868]\t Bias: [2.50570593]\t Cost: 15.565063318657389\n",
            "Iteration: 672\t Weight: [9.69081861]\t Bias: [2.50570638]\t Cost: 15.565063318553229\n",
            "Iteration: 673\t Weight: [9.69081854]\t Bias: [2.50570684]\t Cost: 15.565063318449146\n",
            "Iteration: 674\t Weight: [9.69081847]\t Bias: [2.50570729]\t Cost: 15.565063318345134\n",
            "Iteration: 675\t Weight: [9.6908184]\t Bias: [2.50570774]\t Cost: 15.5650633182412\n",
            "Iteration: 676\t Weight: [9.69081833]\t Bias: [2.50570819]\t Cost: 15.565063318137339\n",
            "Iteration: 677\t Weight: [9.69081826]\t Bias: [2.50570864]\t Cost: 15.565063318033554\n",
            "Iteration: 678\t Weight: [9.69081819]\t Bias: [2.50570909]\t Cost: 15.565063317929845\n",
            "Iteration: 679\t Weight: [9.69081812]\t Bias: [2.50570954]\t Cost: 15.565063317826215\n",
            "Iteration: 680\t Weight: [9.69081805]\t Bias: [2.50570999]\t Cost: 15.56506331772265\n",
            "Iteration: 681\t Weight: [9.69081798]\t Bias: [2.50571044]\t Cost: 15.565063317619176\n",
            "Iteration: 682\t Weight: [9.69081791]\t Bias: [2.50571089]\t Cost: 15.565063317515762\n",
            "Iteration: 683\t Weight: [9.69081784]\t Bias: [2.50571134]\t Cost: 15.565063317412422\n",
            "Iteration: 684\t Weight: [9.69081777]\t Bias: [2.50571178]\t Cost: 15.565063317309166\n",
            "Iteration: 685\t Weight: [9.6908177]\t Bias: [2.50571223]\t Cost: 15.56506331720597\n",
            "Iteration: 686\t Weight: [9.69081763]\t Bias: [2.50571268]\t Cost: 15.565063317102869\n",
            "Iteration: 687\t Weight: [9.69081756]\t Bias: [2.50571313]\t Cost: 15.565063316999831\n",
            "Iteration: 688\t Weight: [9.69081749]\t Bias: [2.50571358]\t Cost: 15.565063316896868\n",
            "Iteration: 689\t Weight: [9.69081742]\t Bias: [2.50571403]\t Cost: 15.565063316793976\n",
            "Iteration: 690\t Weight: [9.69081735]\t Bias: [2.50571448]\t Cost: 15.565063316691159\n",
            "Iteration: 691\t Weight: [9.69081728]\t Bias: [2.50571492]\t Cost: 15.565063316588418\n",
            "Iteration: 692\t Weight: [9.69081721]\t Bias: [2.50571537]\t Cost: 15.565063316485752\n",
            "Iteration: 693\t Weight: [9.69081715]\t Bias: [2.50571582]\t Cost: 15.565063316383167\n",
            "Iteration: 694\t Weight: [9.69081708]\t Bias: [2.50571627]\t Cost: 15.565063316280655\n",
            "Iteration: 695\t Weight: [9.69081701]\t Bias: [2.50571671]\t Cost: 15.565063316178202\n",
            "Iteration: 696\t Weight: [9.69081694]\t Bias: [2.50571716]\t Cost: 15.565063316075832\n",
            "Iteration: 697\t Weight: [9.69081687]\t Bias: [2.50571761]\t Cost: 15.56506331597354\n",
            "Iteration: 698\t Weight: [9.6908168]\t Bias: [2.50571805]\t Cost: 15.565063315871324\n",
            "Iteration: 699\t Weight: [9.69081673]\t Bias: [2.5057185]\t Cost: 15.565063315769171\n",
            "Iteration: 700\t Weight: [9.69081666]\t Bias: [2.50571895]\t Cost: 15.565063315667102\n",
            "Iteration: 701\t Weight: [9.69081659]\t Bias: [2.50571939]\t Cost: 15.565063315565101\n",
            "Iteration: 702\t Weight: [9.69081652]\t Bias: [2.50571984]\t Cost: 15.56506331546317\n",
            "Iteration: 703\t Weight: [9.69081645]\t Bias: [2.50572029]\t Cost: 15.565063315361316\n",
            "Iteration: 704\t Weight: [9.69081638]\t Bias: [2.50572073]\t Cost: 15.56506331525954\n",
            "Iteration: 705\t Weight: [9.69081631]\t Bias: [2.50572118]\t Cost: 15.565063315157841\n",
            "Iteration: 706\t Weight: [9.69081624]\t Bias: [2.50572162]\t Cost: 15.565063315056198\n",
            "Iteration: 707\t Weight: [9.69081617]\t Bias: [2.50572207]\t Cost: 15.565063314954639\n",
            "Iteration: 708\t Weight: [9.69081611]\t Bias: [2.50572251]\t Cost: 15.565063314853152\n",
            "Iteration: 709\t Weight: [9.69081604]\t Bias: [2.50572296]\t Cost: 15.565063314751743\n",
            "Iteration: 710\t Weight: [9.69081597]\t Bias: [2.5057234]\t Cost: 15.565063314650398\n",
            "Iteration: 711\t Weight: [9.6908159]\t Bias: [2.50572385]\t Cost: 15.565063314549148\n",
            "Iteration: 712\t Weight: [9.69081583]\t Bias: [2.50572429]\t Cost: 15.565063314447945\n",
            "Iteration: 713\t Weight: [9.69081576]\t Bias: [2.50572474]\t Cost: 15.565063314346826\n",
            "Iteration: 714\t Weight: [9.69081569]\t Bias: [2.50572518]\t Cost: 15.565063314245776\n",
            "Iteration: 715\t Weight: [9.69081562]\t Bias: [2.50572563]\t Cost: 15.565063314144806\n",
            "Iteration: 716\t Weight: [9.69081555]\t Bias: [2.50572607]\t Cost: 15.5650633140439\n",
            "Iteration: 717\t Weight: [9.69081548]\t Bias: [2.50572651]\t Cost: 15.565063313943071\n",
            "Iteration: 718\t Weight: [9.69081541]\t Bias: [2.50572696]\t Cost: 15.565063313842327\n",
            "Iteration: 719\t Weight: [9.69081535]\t Bias: [2.5057274]\t Cost: 15.565063313741645\n",
            "Iteration: 720\t Weight: [9.69081528]\t Bias: [2.50572784]\t Cost: 15.565063313641021\n",
            "Iteration: 721\t Weight: [9.69081521]\t Bias: [2.50572829]\t Cost: 15.565063313540492\n",
            "Iteration: 722\t Weight: [9.69081514]\t Bias: [2.50572873]\t Cost: 15.565063313440024\n",
            "Iteration: 723\t Weight: [9.69081507]\t Bias: [2.50572917]\t Cost: 15.56506331333963\n",
            "Iteration: 724\t Weight: [9.690815]\t Bias: [2.50572962]\t Cost: 15.565063313239314\n",
            "Iteration: 725\t Weight: [9.69081493]\t Bias: [2.50573006]\t Cost: 15.565063313139069\n",
            "Iteration: 726\t Weight: [9.69081486]\t Bias: [2.5057305]\t Cost: 15.565063313038893\n",
            "Iteration: 727\t Weight: [9.6908148]\t Bias: [2.50573094]\t Cost: 15.565063312938797\n",
            "Iteration: 728\t Weight: [9.69081473]\t Bias: [2.50573139]\t Cost: 15.565063312838767\n",
            "Iteration: 729\t Weight: [9.69081466]\t Bias: [2.50573183]\t Cost: 15.565063312738811\n",
            "Iteration: 730\t Weight: [9.69081459]\t Bias: [2.50573227]\t Cost: 15.565063312638918\n",
            "Iteration: 731\t Weight: [9.69081452]\t Bias: [2.50573271]\t Cost: 15.565063312539106\n",
            "Iteration: 732\t Weight: [9.69081445]\t Bias: [2.50573315]\t Cost: 15.565063312439367\n",
            "Iteration: 733\t Weight: [9.69081438]\t Bias: [2.50573359]\t Cost: 15.565063312339706\n",
            "Iteration: 734\t Weight: [9.69081432]\t Bias: [2.50573403]\t Cost: 15.565063312240099\n",
            "Iteration: 735\t Weight: [9.69081425]\t Bias: [2.50573447]\t Cost: 15.565063312140571\n",
            "Iteration: 736\t Weight: [9.69081418]\t Bias: [2.50573492]\t Cost: 15.565063312041115\n",
            "Iteration: 737\t Weight: [9.69081411]\t Bias: [2.50573536]\t Cost: 15.565063311941742\n",
            "Iteration: 738\t Weight: [9.69081404]\t Bias: [2.5057358]\t Cost: 15.565063311842428\n",
            "Iteration: 739\t Weight: [9.69081397]\t Bias: [2.50573624]\t Cost: 15.565063311743199\n",
            "Iteration: 740\t Weight: [9.69081391]\t Bias: [2.50573668]\t Cost: 15.565063311644028\n",
            "Iteration: 741\t Weight: [9.69081384]\t Bias: [2.50573712]\t Cost: 15.565063311544932\n",
            "Iteration: 742\t Weight: [9.69081377]\t Bias: [2.50573756]\t Cost: 15.565063311445904\n",
            "Iteration: 743\t Weight: [9.6908137]\t Bias: [2.505738]\t Cost: 15.565063311346954\n",
            "Iteration: 744\t Weight: [9.69081363]\t Bias: [2.50573844]\t Cost: 15.565063311248085\n",
            "Iteration: 745\t Weight: [9.69081356]\t Bias: [2.50573887]\t Cost: 15.565063311149272\n",
            "Iteration: 746\t Weight: [9.6908135]\t Bias: [2.50573931]\t Cost: 15.565063311050531\n",
            "Iteration: 747\t Weight: [9.69081343]\t Bias: [2.50573975]\t Cost: 15.56506331095186\n",
            "Iteration: 748\t Weight: [9.69081336]\t Bias: [2.50574019]\t Cost: 15.565063310853276\n",
            "Iteration: 749\t Weight: [9.69081329]\t Bias: [2.50574063]\t Cost: 15.565063310754747\n",
            "Iteration: 750\t Weight: [9.69081322]\t Bias: [2.50574107]\t Cost: 15.565063310656292\n",
            "Iteration: 751\t Weight: [9.69081315]\t Bias: [2.50574151]\t Cost: 15.565063310557914\n",
            "Iteration: 752\t Weight: [9.69081309]\t Bias: [2.50574195]\t Cost: 15.565063310459612\n",
            "Iteration: 753\t Weight: [9.69081302]\t Bias: [2.50574238]\t Cost: 15.565063310361362\n",
            "Iteration: 754\t Weight: [9.69081295]\t Bias: [2.50574282]\t Cost: 15.565063310263199\n",
            "Iteration: 755\t Weight: [9.69081288]\t Bias: [2.50574326]\t Cost: 15.565063310165097\n",
            "Iteration: 756\t Weight: [9.69081281]\t Bias: [2.5057437]\t Cost: 15.56506331006707\n",
            "Iteration: 757\t Weight: [9.69081275]\t Bias: [2.50574413]\t Cost: 15.565063309969114\n",
            "Iteration: 758\t Weight: [9.69081268]\t Bias: [2.50574457]\t Cost: 15.565063309871235\n",
            "Iteration: 759\t Weight: [9.69081261]\t Bias: [2.50574501]\t Cost: 15.565063309773413\n",
            "Iteration: 760\t Weight: [9.69081254]\t Bias: [2.50574545]\t Cost: 15.565063309675672\n",
            "Iteration: 761\t Weight: [9.69081248]\t Bias: [2.50574588]\t Cost: 15.56506330957801\n",
            "Iteration: 762\t Weight: [9.69081241]\t Bias: [2.50574632]\t Cost: 15.565063309480383\n",
            "Iteration: 763\t Weight: [9.69081234]\t Bias: [2.50574676]\t Cost: 15.565063309382856\n",
            "Iteration: 764\t Weight: [9.69081227]\t Bias: [2.50574719]\t Cost: 15.56506330928541\n",
            "Iteration: 765\t Weight: [9.6908122]\t Bias: [2.50574763]\t Cost: 15.565063309188023\n",
            "Iteration: 766\t Weight: [9.69081214]\t Bias: [2.50574806]\t Cost: 15.565063309090695\n",
            "Iteration: 767\t Weight: [9.69081207]\t Bias: [2.5057485]\t Cost: 15.565063308993443\n",
            "Iteration: 768\t Weight: [9.690812]\t Bias: [2.50574894]\t Cost: 15.565063308896267\n",
            "Iteration: 769\t Weight: [9.69081193]\t Bias: [2.50574937]\t Cost: 15.565063308799155\n",
            "Iteration: 770\t Weight: [9.69081187]\t Bias: [2.50574981]\t Cost: 15.565063308702115\n",
            "Iteration: 771\t Weight: [9.6908118]\t Bias: [2.50575024]\t Cost: 15.565063308605144\n",
            "Iteration: 772\t Weight: [9.69081173]\t Bias: [2.50575068]\t Cost: 15.565063308508243\n",
            "Iteration: 773\t Weight: [9.69081166]\t Bias: [2.50575111]\t Cost: 15.56506330841141\n",
            "Iteration: 774\t Weight: [9.6908116]\t Bias: [2.50575155]\t Cost: 15.565063308314649\n",
            "Iteration: 775\t Weight: [9.69081153]\t Bias: [2.50575198]\t Cost: 15.565063308217962\n",
            "Iteration: 776\t Weight: [9.69081146]\t Bias: [2.50575242]\t Cost: 15.565063308121347\n",
            "Iteration: 777\t Weight: [9.69081139]\t Bias: [2.50575285]\t Cost: 15.565063308024794\n",
            "Iteration: 778\t Weight: [9.69081133]\t Bias: [2.50575328]\t Cost: 15.56506330792831\n",
            "Iteration: 779\t Weight: [9.69081126]\t Bias: [2.50575372]\t Cost: 15.565063307831899\n",
            "Iteration: 780\t Weight: [9.69081119]\t Bias: [2.50575415]\t Cost: 15.565063307735562\n",
            "Iteration: 781\t Weight: [9.69081112]\t Bias: [2.50575458]\t Cost: 15.565063307639289\n",
            "Iteration: 782\t Weight: [9.69081106]\t Bias: [2.50575502]\t Cost: 15.565063307543088\n",
            "Iteration: 783\t Weight: [9.69081099]\t Bias: [2.50575545]\t Cost: 15.565063307446957\n",
            "Iteration: 784\t Weight: [9.69081092]\t Bias: [2.50575588]\t Cost: 15.565063307350885\n",
            "Iteration: 785\t Weight: [9.69081085]\t Bias: [2.50575632]\t Cost: 15.565063307254896\n",
            "Iteration: 786\t Weight: [9.69081079]\t Bias: [2.50575675]\t Cost: 15.565063307158967\n",
            "Iteration: 787\t Weight: [9.69081072]\t Bias: [2.50575718]\t Cost: 15.565063307063113\n",
            "Iteration: 788\t Weight: [9.69081065]\t Bias: [2.50575762]\t Cost: 15.565063306967332\n",
            "Iteration: 789\t Weight: [9.69081059]\t Bias: [2.50575805]\t Cost: 15.565063306871613\n",
            "Iteration: 790\t Weight: [9.69081052]\t Bias: [2.50575848]\t Cost: 15.565063306775963\n",
            "Iteration: 791\t Weight: [9.69081045]\t Bias: [2.50575891]\t Cost: 15.56506330668038\n",
            "Iteration: 792\t Weight: [9.69081038]\t Bias: [2.50575934]\t Cost: 15.565063306584866\n",
            "Iteration: 793\t Weight: [9.69081032]\t Bias: [2.50575978]\t Cost: 15.565063306489439\n",
            "Iteration: 794\t Weight: [9.69081025]\t Bias: [2.50576021]\t Cost: 15.565063306394059\n",
            "Iteration: 795\t Weight: [9.69081018]\t Bias: [2.50576064]\t Cost: 15.565063306298766\n",
            "Iteration: 796\t Weight: [9.69081012]\t Bias: [2.50576107]\t Cost: 15.565063306203527\n",
            "Iteration: 797\t Weight: [9.69081005]\t Bias: [2.5057615]\t Cost: 15.565063306108357\n",
            "Iteration: 798\t Weight: [9.69080998]\t Bias: [2.50576193]\t Cost: 15.565063306013261\n",
            "Iteration: 799\t Weight: [9.69080991]\t Bias: [2.50576236]\t Cost: 15.565063305918237\n",
            "Iteration: 800\t Weight: [9.69080985]\t Bias: [2.50576279]\t Cost: 15.565063305823276\n",
            "Iteration: 801\t Weight: [9.69080978]\t Bias: [2.50576322]\t Cost: 15.565063305728385\n",
            "Iteration: 802\t Weight: [9.69080971]\t Bias: [2.50576366]\t Cost: 15.565063305633567\n",
            "Iteration: 803\t Weight: [9.69080965]\t Bias: [2.50576409]\t Cost: 15.56506330553882\n",
            "Iteration: 804\t Weight: [9.69080958]\t Bias: [2.50576452]\t Cost: 15.565063305444124\n",
            "Iteration: 805\t Weight: [9.69080951]\t Bias: [2.50576495]\t Cost: 15.565063305349511\n",
            "Iteration: 806\t Weight: [9.69080945]\t Bias: [2.50576538]\t Cost: 15.565063305254963\n",
            "Iteration: 807\t Weight: [9.69080938]\t Bias: [2.5057658]\t Cost: 15.565063305160466\n",
            "Iteration: 808\t Weight: [9.69080931]\t Bias: [2.50576623]\t Cost: 15.56506330506607\n",
            "Iteration: 809\t Weight: [9.69080925]\t Bias: [2.50576666]\t Cost: 15.565063304971723\n",
            "Iteration: 810\t Weight: [9.69080918]\t Bias: [2.50576709]\t Cost: 15.565063304877452\n",
            "Iteration: 811\t Weight: [9.69080911]\t Bias: [2.50576752]\t Cost: 15.56506330478324\n",
            "Iteration: 812\t Weight: [9.69080905]\t Bias: [2.50576795]\t Cost: 15.5650633046891\n",
            "Iteration: 813\t Weight: [9.69080898]\t Bias: [2.50576838]\t Cost: 15.565063304595032\n",
            "Iteration: 814\t Weight: [9.69080891]\t Bias: [2.50576881]\t Cost: 15.565063304501018\n",
            "Iteration: 815\t Weight: [9.69080885]\t Bias: [2.50576924]\t Cost: 15.56506330440709\n",
            "Iteration: 816\t Weight: [9.69080878]\t Bias: [2.50576966]\t Cost: 15.565063304313227\n",
            "Iteration: 817\t Weight: [9.69080871]\t Bias: [2.50577009]\t Cost: 15.565063304219432\n",
            "Iteration: 818\t Weight: [9.69080865]\t Bias: [2.50577052]\t Cost: 15.565063304125692\n",
            "Iteration: 819\t Weight: [9.69080858]\t Bias: [2.50577095]\t Cost: 15.565063304032023\n",
            "Iteration: 820\t Weight: [9.69080852]\t Bias: [2.50577138]\t Cost: 15.565063303938427\n",
            "Iteration: 821\t Weight: [9.69080845]\t Bias: [2.5057718]\t Cost: 15.5650633038449\n",
            "Iteration: 822\t Weight: [9.69080838]\t Bias: [2.50577223]\t Cost: 15.56506330375143\n",
            "Iteration: 823\t Weight: [9.69080832]\t Bias: [2.50577266]\t Cost: 15.565063303658038\n",
            "Iteration: 824\t Weight: [9.69080825]\t Bias: [2.50577308]\t Cost: 15.56506330356472\n",
            "Iteration: 825\t Weight: [9.69080818]\t Bias: [2.50577351]\t Cost: 15.565063303471462\n",
            "Iteration: 826\t Weight: [9.69080812]\t Bias: [2.50577394]\t Cost: 15.565063303378269\n",
            "Iteration: 827\t Weight: [9.69080805]\t Bias: [2.50577436]\t Cost: 15.565063303285136\n",
            "Iteration: 828\t Weight: [9.69080798]\t Bias: [2.50577479]\t Cost: 15.565063303192094\n",
            "Iteration: 829\t Weight: [9.69080792]\t Bias: [2.50577522]\t Cost: 15.565063303099084\n",
            "Iteration: 830\t Weight: [9.69080785]\t Bias: [2.50577564]\t Cost: 15.565063303006175\n",
            "Iteration: 831\t Weight: [9.69080779]\t Bias: [2.50577607]\t Cost: 15.56506330291331\n",
            "Iteration: 832\t Weight: [9.69080772]\t Bias: [2.50577649]\t Cost: 15.565063302820516\n",
            "Iteration: 833\t Weight: [9.69080765]\t Bias: [2.50577692]\t Cost: 15.5650633027278\n",
            "Iteration: 834\t Weight: [9.69080759]\t Bias: [2.50577735]\t Cost: 15.565063302635146\n",
            "Iteration: 835\t Weight: [9.69080752]\t Bias: [2.50577777]\t Cost: 15.56506330254256\n",
            "Iteration: 836\t Weight: [9.69080746]\t Bias: [2.5057782]\t Cost: 15.565063302450044\n",
            "Iteration: 837\t Weight: [9.69080739]\t Bias: [2.50577862]\t Cost: 15.565063302357586\n",
            "Iteration: 838\t Weight: [9.69080732]\t Bias: [2.50577905]\t Cost: 15.565063302265202\n",
            "Iteration: 839\t Weight: [9.69080726]\t Bias: [2.50577947]\t Cost: 15.565063302172877\n",
            "Iteration: 840\t Weight: [9.69080719]\t Bias: [2.50577989]\t Cost: 15.565063302080619\n",
            "Iteration: 841\t Weight: [9.69080713]\t Bias: [2.50578032]\t Cost: 15.565063301988433\n",
            "Iteration: 842\t Weight: [9.69080706]\t Bias: [2.50578074]\t Cost: 15.565063301896314\n",
            "Iteration: 843\t Weight: [9.69080699]\t Bias: [2.50578117]\t Cost: 15.565063301804262\n",
            "Iteration: 844\t Weight: [9.69080693]\t Bias: [2.50578159]\t Cost: 15.565063301712268\n",
            "Iteration: 845\t Weight: [9.69080686]\t Bias: [2.50578201]\t Cost: 15.565063301620341\n",
            "Iteration: 846\t Weight: [9.6908068]\t Bias: [2.50578244]\t Cost: 15.56506330152849\n",
            "Iteration: 847\t Weight: [9.69080673]\t Bias: [2.50578286]\t Cost: 15.565063301436707\n",
            "Iteration: 848\t Weight: [9.69080667]\t Bias: [2.50578328]\t Cost: 15.565063301344985\n",
            "Iteration: 849\t Weight: [9.6908066]\t Bias: [2.50578371]\t Cost: 15.565063301253327\n",
            "Iteration: 850\t Weight: [9.69080653]\t Bias: [2.50578413]\t Cost: 15.565063301161732\n",
            "Iteration: 851\t Weight: [9.69080647]\t Bias: [2.50578455]\t Cost: 15.565063301070216\n",
            "Iteration: 852\t Weight: [9.6908064]\t Bias: [2.50578498]\t Cost: 15.565063300978746\n",
            "Iteration: 853\t Weight: [9.69080634]\t Bias: [2.5057854]\t Cost: 15.565063300887358\n",
            "Iteration: 854\t Weight: [9.69080627]\t Bias: [2.50578582]\t Cost: 15.565063300796034\n",
            "Iteration: 855\t Weight: [9.69080621]\t Bias: [2.50578624]\t Cost: 15.565063300704777\n",
            "Iteration: 856\t Weight: [9.69080614]\t Bias: [2.50578667]\t Cost: 15.56506330061358\n",
            "Iteration: 857\t Weight: [9.69080607]\t Bias: [2.50578709]\t Cost: 15.565063300522446\n",
            "Iteration: 858\t Weight: [9.69080601]\t Bias: [2.50578751]\t Cost: 15.5650633004314\n",
            "Iteration: 859\t Weight: [9.69080594]\t Bias: [2.50578793]\t Cost: 15.565063300340396\n",
            "Iteration: 860\t Weight: [9.69080588]\t Bias: [2.50578835]\t Cost: 15.565063300249468\n",
            "Iteration: 861\t Weight: [9.69080581]\t Bias: [2.50578877]\t Cost: 15.565063300158595\n",
            "Iteration: 862\t Weight: [9.69080575]\t Bias: [2.50578919]\t Cost: 15.5650633000678\n",
            "Iteration: 863\t Weight: [9.69080568]\t Bias: [2.50578962]\t Cost: 15.565063299977062\n",
            "Iteration: 864\t Weight: [9.69080562]\t Bias: [2.50579004]\t Cost: 15.565063299886392\n",
            "Iteration: 865\t Weight: [9.69080555]\t Bias: [2.50579046]\t Cost: 15.565063299795806\n",
            "Iteration: 866\t Weight: [9.69080549]\t Bias: [2.50579088]\t Cost: 15.565063299705262\n",
            "Iteration: 867\t Weight: [9.69080542]\t Bias: [2.5057913]\t Cost: 15.565063299614781\n",
            "Iteration: 868\t Weight: [9.69080536]\t Bias: [2.50579172]\t Cost: 15.565063299524383\n",
            "Iteration: 869\t Weight: [9.69080529]\t Bias: [2.50579214]\t Cost: 15.565063299434037\n",
            "Iteration: 870\t Weight: [9.69080522]\t Bias: [2.50579256]\t Cost: 15.565063299343759\n",
            "Iteration: 871\t Weight: [9.69080516]\t Bias: [2.50579298]\t Cost: 15.565063299253548\n",
            "Iteration: 872\t Weight: [9.69080509]\t Bias: [2.5057934]\t Cost: 15.565063299163397\n",
            "Iteration: 873\t Weight: [9.69080503]\t Bias: [2.50579382]\t Cost: 15.565063299073326\n",
            "Iteration: 874\t Weight: [9.69080496]\t Bias: [2.50579424]\t Cost: 15.565063298983306\n",
            "Iteration: 875\t Weight: [9.6908049]\t Bias: [2.50579466]\t Cost: 15.565063298893355\n",
            "Iteration: 876\t Weight: [9.69080483]\t Bias: [2.50579507]\t Cost: 15.565063298803468\n",
            "Iteration: 877\t Weight: [9.69080477]\t Bias: [2.50579549]\t Cost: 15.565063298713651\n",
            "Iteration: 878\t Weight: [9.6908047]\t Bias: [2.50579591]\t Cost: 15.565063298623894\n",
            "Iteration: 879\t Weight: [9.69080464]\t Bias: [2.50579633]\t Cost: 15.565063298534204\n",
            "Iteration: 880\t Weight: [9.69080457]\t Bias: [2.50579675]\t Cost: 15.565063298444572\n",
            "Iteration: 881\t Weight: [9.69080451]\t Bias: [2.50579717]\t Cost: 15.565063298355017\n",
            "Iteration: 882\t Weight: [9.69080444]\t Bias: [2.50579759]\t Cost: 15.565063298265514\n",
            "Iteration: 883\t Weight: [9.69080438]\t Bias: [2.505798]\t Cost: 15.565063298176073\n",
            "Iteration: 884\t Weight: [9.69080431]\t Bias: [2.50579842]\t Cost: 15.565063298086729\n",
            "Iteration: 885\t Weight: [9.69080425]\t Bias: [2.50579884]\t Cost: 15.565063297997416\n",
            "Iteration: 886\t Weight: [9.69080418]\t Bias: [2.50579926]\t Cost: 15.565063297908178\n",
            "Iteration: 887\t Weight: [9.69080412]\t Bias: [2.50579967]\t Cost: 15.565063297819004\n",
            "Iteration: 888\t Weight: [9.69080405]\t Bias: [2.50580009]\t Cost: 15.565063297729896\n",
            "Iteration: 889\t Weight: [9.69080399]\t Bias: [2.50580051]\t Cost: 15.565063297640851\n",
            "Iteration: 890\t Weight: [9.69080392]\t Bias: [2.50580092]\t Cost: 15.565063297551868\n",
            "Iteration: 891\t Weight: [9.69080386]\t Bias: [2.50580134]\t Cost: 15.56506329746295\n",
            "Iteration: 892\t Weight: [9.6908038]\t Bias: [2.50580176]\t Cost: 15.5650632973741\n",
            "Iteration: 893\t Weight: [9.69080373]\t Bias: [2.50580217]\t Cost: 15.565063297285308\n",
            "Iteration: 894\t Weight: [9.69080367]\t Bias: [2.50580259]\t Cost: 15.565063297196586\n",
            "Iteration: 895\t Weight: [9.6908036]\t Bias: [2.50580301]\t Cost: 15.565063297107931\n",
            "Iteration: 896\t Weight: [9.69080354]\t Bias: [2.50580342]\t Cost: 15.565063297019334\n",
            "Iteration: 897\t Weight: [9.69080347]\t Bias: [2.50580384]\t Cost: 15.565063296930793\n",
            "Iteration: 898\t Weight: [9.69080341]\t Bias: [2.50580425]\t Cost: 15.565063296842336\n",
            "Iteration: 899\t Weight: [9.69080334]\t Bias: [2.50580467]\t Cost: 15.565063296753928\n",
            "Iteration: 900\t Weight: [9.69080328]\t Bias: [2.50580509]\t Cost: 15.565063296665578\n",
            "Iteration: 901\t Weight: [9.69080321]\t Bias: [2.5058055]\t Cost: 15.56506329657731\n",
            "Iteration: 902\t Weight: [9.69080315]\t Bias: [2.50580592]\t Cost: 15.565063296489093\n",
            "Iteration: 903\t Weight: [9.69080309]\t Bias: [2.50580633]\t Cost: 15.56506329640094\n",
            "Iteration: 904\t Weight: [9.69080302]\t Bias: [2.50580675]\t Cost: 15.565063296312854\n",
            "Iteration: 905\t Weight: [9.69080296]\t Bias: [2.50580716]\t Cost: 15.56506329622484\n",
            "Iteration: 906\t Weight: [9.69080289]\t Bias: [2.50580757]\t Cost: 15.565063296136874\n",
            "Iteration: 907\t Weight: [9.69080283]\t Bias: [2.50580799]\t Cost: 15.565063296048983\n",
            "Iteration: 908\t Weight: [9.69080276]\t Bias: [2.5058084]\t Cost: 15.56506329596115\n",
            "Iteration: 909\t Weight: [9.6908027]\t Bias: [2.50580882]\t Cost: 15.565063295873381\n",
            "Iteration: 910\t Weight: [9.69080263]\t Bias: [2.50580923]\t Cost: 15.56506329578567\n",
            "Iteration: 911\t Weight: [9.69080257]\t Bias: [2.50580964]\t Cost: 15.565063295698044\n",
            "Iteration: 912\t Weight: [9.69080251]\t Bias: [2.50581006]\t Cost: 15.56506329561046\n",
            "Iteration: 913\t Weight: [9.69080244]\t Bias: [2.50581047]\t Cost: 15.565063295522954\n",
            "Iteration: 914\t Weight: [9.69080238]\t Bias: [2.50581088]\t Cost: 15.565063295435495\n",
            "Iteration: 915\t Weight: [9.69080231]\t Bias: [2.5058113]\t Cost: 15.565063295348105\n",
            "Iteration: 916\t Weight: [9.69080225]\t Bias: [2.50581171]\t Cost: 15.56506329526078\n",
            "Iteration: 917\t Weight: [9.69080219]\t Bias: [2.50581212]\t Cost: 15.56506329517352\n",
            "Iteration: 918\t Weight: [9.69080212]\t Bias: [2.50581254]\t Cost: 15.565063295086318\n",
            "Iteration: 919\t Weight: [9.69080206]\t Bias: [2.50581295]\t Cost: 15.565063294999186\n",
            "Iteration: 920\t Weight: [9.69080199]\t Bias: [2.50581336]\t Cost: 15.565063294912115\n",
            "Iteration: 921\t Weight: [9.69080193]\t Bias: [2.50581377]\t Cost: 15.565063294825094\n",
            "Iteration: 922\t Weight: [9.69080186]\t Bias: [2.50581419]\t Cost: 15.56506329473815\n",
            "Iteration: 923\t Weight: [9.6908018]\t Bias: [2.5058146]\t Cost: 15.56506329465127\n",
            "Iteration: 924\t Weight: [9.69080174]\t Bias: [2.50581501]\t Cost: 15.565063294564446\n",
            "Iteration: 925\t Weight: [9.69080167]\t Bias: [2.50581542]\t Cost: 15.56506329447768\n",
            "Iteration: 926\t Weight: [9.69080161]\t Bias: [2.50581583]\t Cost: 15.565063294390992\n",
            "Iteration: 927\t Weight: [9.69080155]\t Bias: [2.50581624]\t Cost: 15.565063294304357\n",
            "Iteration: 928\t Weight: [9.69080148]\t Bias: [2.50581666]\t Cost: 15.565063294217788\n",
            "Iteration: 929\t Weight: [9.69080142]\t Bias: [2.50581707]\t Cost: 15.565063294131274\n",
            "Iteration: 930\t Weight: [9.69080135]\t Bias: [2.50581748]\t Cost: 15.565063294044828\n",
            "Iteration: 931\t Weight: [9.69080129]\t Bias: [2.50581789]\t Cost: 15.565063293958442\n",
            "Iteration: 932\t Weight: [9.69080123]\t Bias: [2.5058183]\t Cost: 15.56506329387213\n",
            "Iteration: 933\t Weight: [9.69080116]\t Bias: [2.50581871]\t Cost: 15.56506329378587\n",
            "Iteration: 934\t Weight: [9.6908011]\t Bias: [2.50581912]\t Cost: 15.56506329369967\n",
            "Iteration: 935\t Weight: [9.69080103]\t Bias: [2.50581953]\t Cost: 15.56506329361354\n",
            "Iteration: 936\t Weight: [9.69080097]\t Bias: [2.50581994]\t Cost: 15.565063293527466\n",
            "Iteration: 937\t Weight: [9.69080091]\t Bias: [2.50582035]\t Cost: 15.565063293441451\n",
            "Iteration: 938\t Weight: [9.69080084]\t Bias: [2.50582076]\t Cost: 15.56506329335551\n",
            "Iteration: 939\t Weight: [9.69080078]\t Bias: [2.50582117]\t Cost: 15.56506329326962\n",
            "Iteration: 940\t Weight: [9.69080072]\t Bias: [2.50582158]\t Cost: 15.565063293183803\n",
            "Iteration: 941\t Weight: [9.69080065]\t Bias: [2.50582199]\t Cost: 15.565063293098033\n",
            "Iteration: 942\t Weight: [9.69080059]\t Bias: [2.5058224]\t Cost: 15.565063293012331\n",
            "Iteration: 943\t Weight: [9.69080053]\t Bias: [2.50582281]\t Cost: 15.565063292926682\n",
            "Iteration: 944\t Weight: [9.69080046]\t Bias: [2.50582321]\t Cost: 15.565063292841115\n",
            "Iteration: 945\t Weight: [9.6908004]\t Bias: [2.50582362]\t Cost: 15.565063292755601\n",
            "Iteration: 946\t Weight: [9.69080034]\t Bias: [2.50582403]\t Cost: 15.565063292670155\n",
            "Iteration: 947\t Weight: [9.69080027]\t Bias: [2.50582444]\t Cost: 15.565063292584753\n",
            "Iteration: 948\t Weight: [9.69080021]\t Bias: [2.50582485]\t Cost: 15.565063292499419\n",
            "Iteration: 949\t Weight: [9.69080015]\t Bias: [2.50582526]\t Cost: 15.565063292414166\n",
            "Iteration: 950\t Weight: [9.69080008]\t Bias: [2.50582566]\t Cost: 15.565063292328954\n",
            "Iteration: 951\t Weight: [9.69080002]\t Bias: [2.50582607]\t Cost: 15.56506329224381\n",
            "Iteration: 952\t Weight: [9.69079996]\t Bias: [2.50582648]\t Cost: 15.565063292158731\n",
            "Iteration: 953\t Weight: [9.69079989]\t Bias: [2.50582689]\t Cost: 15.565063292073713\n",
            "Iteration: 954\t Weight: [9.69079983]\t Bias: [2.50582729]\t Cost: 15.56506329198874\n",
            "Iteration: 955\t Weight: [9.69079977]\t Bias: [2.5058277]\t Cost: 15.565063291903847\n",
            "Iteration: 956\t Weight: [9.6907997]\t Bias: [2.50582811]\t Cost: 15.565063291819\n",
            "Iteration: 957\t Weight: [9.69079964]\t Bias: [2.50582852]\t Cost: 15.56506329173423\n",
            "Iteration: 958\t Weight: [9.69079958]\t Bias: [2.50582892]\t Cost: 15.565063291649524\n",
            "Iteration: 959\t Weight: [9.69079951]\t Bias: [2.50582933]\t Cost: 15.565063291564863\n",
            "Iteration: 960\t Weight: [9.69079945]\t Bias: [2.50582974]\t Cost: 15.565063291480277\n",
            "Iteration: 961\t Weight: [9.69079939]\t Bias: [2.50583014]\t Cost: 15.565063291395745\n",
            "Iteration: 962\t Weight: [9.69079932]\t Bias: [2.50583055]\t Cost: 15.56506329131127\n",
            "Iteration: 963\t Weight: [9.69079926]\t Bias: [2.50583095]\t Cost: 15.565063291226856\n",
            "Iteration: 964\t Weight: [9.6907992]\t Bias: [2.50583136]\t Cost: 15.565063291142517\n",
            "Iteration: 965\t Weight: [9.69079913]\t Bias: [2.50583177]\t Cost: 15.565063291058223\n",
            "Iteration: 966\t Weight: [9.69079907]\t Bias: [2.50583217]\t Cost: 15.565063290973995\n",
            "Iteration: 967\t Weight: [9.69079901]\t Bias: [2.50583258]\t Cost: 15.565063290889832\n",
            "Iteration: 968\t Weight: [9.69079895]\t Bias: [2.50583298]\t Cost: 15.565063290805725\n",
            "Iteration: 969\t Weight: [9.69079888]\t Bias: [2.50583339]\t Cost: 15.565063290721682\n",
            "Iteration: 970\t Weight: [9.69079882]\t Bias: [2.50583379]\t Cost: 15.56506329063769\n",
            "Iteration: 971\t Weight: [9.69079876]\t Bias: [2.5058342]\t Cost: 15.565063290553773\n",
            "Iteration: 972\t Weight: [9.69079869]\t Bias: [2.5058346]\t Cost: 15.56506329046991\n",
            "Iteration: 973\t Weight: [9.69079863]\t Bias: [2.50583501]\t Cost: 15.565063290386108\n",
            "Iteration: 974\t Weight: [9.69079857]\t Bias: [2.50583541]\t Cost: 15.565063290302371\n",
            "Iteration: 975\t Weight: [9.6907985]\t Bias: [2.50583582]\t Cost: 15.565063290218685\n",
            "Iteration: 976\t Weight: [9.69079844]\t Bias: [2.50583622]\t Cost: 15.565063290135067\n",
            "Iteration: 977\t Weight: [9.69079838]\t Bias: [2.50583662]\t Cost: 15.565063290051505\n",
            "Iteration: 978\t Weight: [9.69079832]\t Bias: [2.50583703]\t Cost: 15.565063289968007\n",
            "Iteration: 979\t Weight: [9.69079825]\t Bias: [2.50583743]\t Cost: 15.565063289884561\n",
            "Iteration: 980\t Weight: [9.69079819]\t Bias: [2.50583783]\t Cost: 15.565063289801188\n",
            "Iteration: 981\t Weight: [9.69079813]\t Bias: [2.50583824]\t Cost: 15.56506328971787\n",
            "Iteration: 982\t Weight: [9.69079807]\t Bias: [2.50583864]\t Cost: 15.565063289634612\n",
            "Iteration: 983\t Weight: [9.690798]\t Bias: [2.50583904]\t Cost: 15.56506328955142\n",
            "Iteration: 984\t Weight: [9.69079794]\t Bias: [2.50583945]\t Cost: 15.565063289468268\n",
            "Iteration: 985\t Weight: [9.69079788]\t Bias: [2.50583985]\t Cost: 15.56506328938519\n",
            "Iteration: 986\t Weight: [9.69079782]\t Bias: [2.50584025]\t Cost: 15.56506328930218\n",
            "Iteration: 987\t Weight: [9.69079775]\t Bias: [2.50584066]\t Cost: 15.565063289219214\n",
            "Iteration: 988\t Weight: [9.69079769]\t Bias: [2.50584106]\t Cost: 15.565063289136322\n",
            "Iteration: 989\t Weight: [9.69079763]\t Bias: [2.50584146]\t Cost: 15.565063289053478\n",
            "Iteration: 990\t Weight: [9.69079757]\t Bias: [2.50584186]\t Cost: 15.565063288970705\n",
            "Iteration: 991\t Weight: [9.6907975]\t Bias: [2.50584226]\t Cost: 15.56506328888798\n",
            "Iteration: 992\t Weight: [9.69079744]\t Bias: [2.50584267]\t Cost: 15.565063288805309\n",
            "Iteration: 993\t Weight: [9.69079738]\t Bias: [2.50584307]\t Cost: 15.565063288722722\n",
            "Iteration: 994\t Weight: [9.69079732]\t Bias: [2.50584347]\t Cost: 15.565063288640182\n",
            "Iteration: 995\t Weight: [9.69079725]\t Bias: [2.50584387]\t Cost: 15.56506328855771\n",
            "Iteration: 996\t Weight: [9.69079719]\t Bias: [2.50584427]\t Cost: 15.565063288475278\n",
            "Iteration: 997\t Weight: [9.69079713]\t Bias: [2.50584467]\t Cost: 15.565063288392922\n",
            "Iteration: 998\t Weight: [9.69079707]\t Bias: [2.50584507]\t Cost: 15.565063288310615\n",
            "Iteration: 999\t Weight: [9.690797]\t Bias: [2.50584547]\t Cost: 15.565063288228378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAXxUlEQVR4nO3df4xd5X3n8ffn3jsz/kWwjSdex3Y7\nbmMl8maTYI2IEdUqirvE0CTmjzQCVcVLLVmrJdu0REqhrYrabqVErUJg1UV1YydmFZGwNC0WoiGO\noUorFcIQEmIwPyb88nhtPIBxAMf2zPi7f5znju/cGTOeuTNz7ed8XtLVnPOc5859jo/1uc9877nn\nKCIwM7NyqLR7AGZmNncc+mZmJeLQNzMrEYe+mVmJOPTNzEqk1u4BvJtly5ZFT09Pu4dhZnZBefzx\nx1+LiO6Jtp3Xod/T00NfX1+7h2FmdkGR9PLZtrm8Y2ZWIg59M7MSceibmZWIQ9/MrEQc+mZmJeLQ\nNzMrEYe+mVmJZBn675wc5qvff5YnXjna7qGYmZ1Xsgz9E0Mj3PFQP08OHGv3UMzMzitZhn61IgBG\nTvsGMWZmjbIM/UoK/dO+K5iZ2RhZhn7NM30zswllGfoVFaE/7NA3Mxsjy9Cv1/RPO/TNzMbIM/TT\nTH/ENX0zszEmDX1JOyUdkbRvgm1flBSSlqV1SbpDUr+kJyWtb+i7RdLz6bFlZndjrIpn+mZmEzqX\nmf43gU3NjZJWA1cCrzQ0XwWsTY9twJ2p71LgVuBjwGXArZKWtDLwyVQr8kzfzKzJpKEfET8E3phg\n023Al4DGZN0M3BWFR4DFklYAnwT2RMQbEXEU2MMEbyQzqSoxcno2X8HM7MIzrZq+pM3AwYj4adOm\nlcCBhvWB1Ha29ol+9zZJfZL6BgcHpzM8ACoVn6dvZtZsyqEvaQHwx8CfzfxwICK2R0RvRPR2d094\nX99zUqtUGB5x6JuZNZrOTP/XgTXATyW9BKwCfizpPwAHgdUNfVeltrO1z5qKPNM3M2s25dCPiJ9F\nxHsjoicieihKNesj4jCwG7g+ncWzATgWEYeAB4ErJS1JH+BemdpmTbUifyPXzKzJuZyyeTfw78AH\nJA1I2vou3R8AXgD6gb8H/jtARLwB/CXwWHr8RWqbNT57x8xsvNpkHSLiukm29zQsB3DjWfrtBHZO\ncXzTVpF8nr6ZWZMsv5ELLu+YmU0k29CvyOUdM7Nm2YZ+teLyjplZs2xDv1aRL61sZtYk29CvVOTz\n9M3MmmQb+sW1dxz6ZmaNsg39SsUXXDMza5Zt6Fd9wTUzs3HyDX2Xd8zMxsk29P1BrpnZeNmGfs3f\nyDUzGyfb0K/I5+mbmTXLNvT9jVwzs/GyDn1fe8fMbKxsQ9+XVjYzGy/b0PdM38xsvGxDvyJ/I9fM\nrFm2oV+t4PKOmVmTc7lH7k5JRyTta2j7a0nPSHpS0j9KWtyw7RZJ/ZKelfTJhvZNqa1f0s0zvytj\n1SoVl3fMzJqcy0z/m8CmprY9wIci4sPAc8AtAJLWAdcC/zE9539LqkqqAn8LXAWsA65LfWdNxV/O\nMjMbZ9LQj4gfAm80tX0/IobT6iPAqrS8Gfh2RJyMiBeBfuCy9OiPiBci4hTw7dR31lSFQ9/MrMlM\n1PR/D/jntLwSONCwbSC1na19HEnbJPVJ6hscHJz2oDzTNzMbr6XQl/QnwDDwrZkZDkTE9ojojYje\n7u7uaf+eqnzBNTOzZrXpPlHSfwU+BWyMGE3Xg8Dqhm6rUhvv0j4rqp7pm5mNM62ZvqRNwJeAz0TE\n8YZNu4FrJXVJWgOsBX4EPAaslbRGUifFh727Wxv6u/Ollc3Mxpt0pi/pbuDjwDJJA8CtFGfrdAF7\nJAE8EhH/LSKeknQP8DRF2efGiBhJv+fzwINAFdgZEU/Nwv6M8k1UzMzGmzT0I+K6CZp3vEv/vwL+\naoL2B4AHpjS6FlQrvrSymVmzjL+R6wuumZk1yzr0/Y1cM7Oxsg394tLK7R6Fmdn5JdvQr1bwTN/M\nrEm+oe+zd8zMxsk29CsVAb68splZo2xDv1p8f8CnbZqZNcg39Ktppu+6vpnZqGxDv6NS7Jpn+mZm\nZ2Qb+tVU0x8ZceibmdVlG/q1ar2m75P1zczqsg39+kzf5R0zszOyDf2aQ9/MbJyMQ7/YNdf0zczO\nyDf0XdM3Mxsn29AfPXvH5R0zs1HZhr5r+mZm42Ub+tX6l7Nc0zczGzVp6EvaKemIpH0NbUsl7ZH0\nfPq5JLVL0h2S+iU9KWl9w3O2pP7PS9oyO7tzhmv6ZmbjnctM/5vApqa2m4G9EbEW2JvWAa4C1qbH\nNuBOKN4kKG6o/jHgMuDW+hvFbKm5pm9mNs6koR8RPwTeaGreDOxKy7uAaxra74rCI8BiSSuATwJ7\nIuKNiDgK7GH8G8mM8pezzMzGm25Nf3lEHErLh4HlaXklcKCh30BqO1v7OJK2SeqT1Dc4ODjN4TWc\np+/QNzMb1fIHuRERwIwla0Rsj4jeiOjt7u6e9u+pz/SHRlzTNzOrm27ov5rKNqSfR1L7QWB1Q79V\nqe1s7bOmo+qavplZs+mG/m6gfgbOFuC+hvbr01k8G4BjqQz0IHClpCXpA9wrU9uscU3fzGy82mQd\nJN0NfBxYJmmA4iycLwP3SNoKvAx8LnV/ALga6AeOAzcARMQbkv4SeCz1+4uIaP5weEa5pm9mNt6k\noR8R151l08YJ+gZw41l+z05g55RG1wLP9M3Mxsv2G7mjl2HwB7lmZqOyDX3P9M3Mxss29Duqrumb\nmTXLNvQ90zczGy/b0B+99o5r+mZmo7IN/WrVM30zs2bZhr5vomJmNl7Goe8Pcs3MmmUc+vXz9B36\nZmZ12YZ+pSIkGPGds8zMRmUb+lDM9l3TNzM7I+vQrzr0zczGyDr0OyoV1/TNzBpkHfrVqlzTNzNr\nkHXou6ZvZjZW1qFfrcjn6ZuZNcg69GuVCkOu6ZuZjco79Kti2DV9M7NRLYW+pD+U9JSkfZLuljRP\n0hpJj0rql/QdSZ2pb1da70/be2ZiB95NrSKfvWNm1mDaoS9pJfD7QG9EfAioAtcCXwFui4j3A0eB\nrekpW4Gjqf221G9WdVQrnPKllc3MRrVa3qkB8yXVgAXAIeATwL1p+y7gmrS8Oa2Ttm+UpBZf/111\n1iq+R66ZWYNph35EHAT+BniFIuyPAY8Db0bEcOo2AKxMyyuBA+m5w6n/Jc2/V9I2SX2S+gYHB6c7\nPKAo7/iDXDOzM1op7yyhmL2vAd4HLAQ2tTqgiNgeEb0R0dvd3d3S7+qoVhjyTN/MbFQr5Z3fBF6M\niMGIGAK+C1wBLE7lHoBVwMG0fBBYDZC2Xwy83sLrT8qhb2Y2Viuh/wqwQdKCVJvfCDwNPAx8NvXZ\nAtyXlnenddL2hyJiVmsvHVWXd8zMGrVS03+U4gPZHwM/S79rO/BHwE2S+ilq9jvSU3YAl6T2m4Cb\nWxj3OfFM38xsrNrkXc4uIm4Fbm1qfgG4bIK+J4DfbuX1psqhb2Y2VtbfyO2o+oJrZmaNsg79WrXC\n0LBn+mZmdVmHfvGNXM/0zczqsg79Tl9wzcxsjKxD3+UdM7Oxsg79jmqFIX+Qa2Y2KvPQF0Mjp5nl\n74CZmV0wMg/9ChH4lolmZkn2oQ/4XH0zsyTz0C8u1+8bqZiZFTIP/TTT97n6ZmZA5qFfSzN9X3/H\nzKyQdejXZ/qnfK6+mRmQeeh3+oNcM7Mxsg59l3fMzMbKOvTr5R2HvplZIfPQr8/0Xd4xM4PsQ98z\nfTOzRi2FvqTFku6V9Iyk/ZIul7RU0h5Jz6efS1JfSbpDUr+kJyWtn5ldODufvWNmNlarM/3bge9F\nxAeBjwD7KW54vjci1gJ7OXMD9KuAtemxDbizxdeeVFfNoW9m1mjaoS/pYuA/AzsAIuJURLwJbAZ2\npW67gGvS8mbgrig8AiyWtGLaIz8HnSn0Tzr0zcyA1mb6a4BB4BuSnpD0dUkLgeURcSj1OQwsT8sr\ngQMNzx9IbWNI2iapT1Lf4OBgC8ODrloV8LV3zMzqWgn9GrAeuDMiLgXe4UwpB4AoLmQ/pVNnImJ7\nRPRGRG93d3cLwztT3jk5NNLS7zEzy0UroT8ADETEo2n9Xoo3gVfrZZv080jafhBY3fD8Valt1ozW\n9D3TNzMDWgj9iDgMHJD0gdS0EXga2A1sSW1bgPvS8m7g+nQWzwbgWEMZaFaM1vSHHPpmZlCUaFrx\nP4BvSeoEXgBuoHgjuUfSVuBl4HOp7wPA1UA/cDz1nVWu6ZuZjdVS6EfET4DeCTZtnKBvADe28npT\n5Zm+mdlYWX8jt1oRtYo4NeIPcs3MIPPQh2K275m+mVkh+9DvqlVc0zczS7IPfc/0zczOKEXoe6Zv\nZlbIPvS7alVODvuDXDMzKEHod1YrvsqmmVmSfeh3dVR8lU0zsyT70O+sOvTNzOqyD/2ujqpD38ws\nyT70XdM3Mzsj+9Avavo+e8fMDEoQ+vNqVX85y8wsyT7053dWOOE7Z5mZAWUI/Y4qv3Tom5kBJQr9\n4nL+Zmblln3oz+usEoFP2zQzowShP7+juGXiL0+5xGNmVp7Qd13fzKz10JdUlfSEpPvT+hpJj0rq\nl/SddNN0JHWl9f60vafV1z4X8zsd+mZmdTMx0/8CsL9h/SvAbRHxfuAosDW1bwWOpvbbUr9ZN8/l\nHTOzUS2FvqRVwG8BX0/rAj4B3Ju67AKuScub0zpp+8bUf1bVyzs+V9/MrPWZ/teALwH1U2MuAd6M\niOG0PgCsTMsrgQMAafux1H8MSdsk9UnqGxwcbHF4Lu+YmTWaduhL+hRwJCIen8HxEBHbI6I3Inq7\nu7tb/n0+e8fM7IxaC8+9AviMpKuBecB7gNuBxZJqaTa/CjiY+h8EVgMDkmrAxcDrLbz+OZnns3fM\nzEZNe6YfEbdExKqI6AGuBR6KiN8BHgY+m7ptAe5Ly7vTOmn7QzEHX5Otl3dc0zczm53z9P8IuElS\nP0XNfkdq3wFcktpvAm6ehdcex+UdM7MzWinvjIqIfwH+JS2/AFw2QZ8TwG/PxOtNRT30j3umb2aW\n/zdy53VUqAiOn3Tom5llH/qSWNhV4+2Tw5N3NjPLXPahD7DIoW9mBpQo9N9x6JuZlSP0Xd4xMyuU\nIvRd3jEzK5Qm9F3eMTMrSegv7Krx9gmHvplZKUJ/UVfV5R0zM8oS+vOKmv4cXOrHzOy8VorQX9hV\n43TAiaHTk3c2M8tYKUL/onkdALx1YqjNIzEza69ShP7i+UXoH/ulQ9/Myq0cob+gCP03HfpmVnLl\nCP35nQC8edyhb2blVo7Qr8/0j59q80jMzNqrFKF/8QLX9M3MoCShf1FXjWpFDn0zK71ph76k1ZIe\nlvS0pKckfSG1L5W0R9Lz6eeS1C5Jd0jql/SkpPUztRPnMFYunt/hmr6ZlV4rM/1h4IsRsQ7YANwo\naR3FDc/3RsRaYC9nboB+FbA2PbYBd7bw2lO2eH4HR13TN7OSm3boR8ShiPhxWn4L2A+sBDYDu1K3\nXcA1aXkzcFcUHgEWS1ox7ZFP0ZKFnQ59Myu9GanpS+oBLgUeBZZHxKG06TCwPC2vBA40PG0gtTX/\nrm2S+iT1DQ4OzsTwAOhe1MXgWydn7PeZmV2IWg59SYuAfwD+ICJ+0bgtiiucTekqZxGxPSJ6I6K3\nu7u71eGN6r7IoW9m1lLoS+qgCPxvRcR3U/Or9bJN+nkktR8EVjc8fVVqmxPdF3Vx9PgQp4Z90TUz\nK69Wzt4RsAPYHxFfbdi0G9iSlrcA9zW0X5/O4tkAHGsoA826ZYu6AHj9Hc/2zay8ai089wrgd4Gf\nSfpJavtj4MvAPZK2Ai8Dn0vbHgCuBvqB48ANLbz2lHVfVIT+4FsnWXHx/Ll8aTOz88a0Qz8i/g3Q\nWTZvnKB/ADdO9/Va9d4U+q/+wjN9MyuvUnwjF2DlkmJ2f/Do8TaPxMysfUoT+pcs7GReR4WBo79s\n91DMzNqmNKEviZWL53PwTYe+mZVXaUIfYNWSBZ7pm1mplSr0Vy+dz0uvv0PxmbKZWfmUKvTXvvci\n3joxzBF/M9fMSqpkob8IgOdefavNIzEza49yhf7yiwB47tW32zwSM7P2KFXoL1vUybJFXew7eKzd\nQzEza4tShb4k1v/KYp545Wi7h2Jm1halCn2A9b+6hJdeP+7LLJtZKZUu9K/49WUA/PC5mbtBi5nZ\nhaJ0of+hle9h+Xu6+P7Th9s9FDOzOVe60JfEpz/8Pn6w/wiHj51o93DMzOZU6UIf4PrLezgdwa5/\nf6ndQzEzm1OlDP1fuWQBn/7w+9jxry/y7GF/UcvMyqOUoQ/wZ59ex0XzatzwjR/5G7pmVhqlDf1l\ni7q4a+tlnBw+zafu+DduuucnfG/fIV55/TgnhkbaPTwzs1mhub7ipKRNwO1AFfh6RHz5bH17e3uj\nr69vVsfz2tsn+doPnuOfnvh/vH1yeLR9QWeVrlqFjmr9ISqa4O6Q59aEJnju2e41aWb2wRXv4X9d\nd+m0nivp8YjonWhbKzdGn85AqsDfAv8FGAAek7Q7Ip6ey3E0Wraoi/95zX/iT39rHc8cfotnD/+C\n194+xdF3TnFq5DRDI6c5NRwMjZym+e1xojfMCd9CJ2iMiXuamQGwOt3idabNaegDlwH9EfECgKRv\nA5uBtoV+3byOKh9dvZiPrl7c7qGYmc2aua7prwQONKwPpLZRkrZJ6pPUNzjob82amc2k8+6D3IjY\nHhG9EdHb3d3d7uGYmWVlrkP/ILC6YX1VajMzszkw16H/GLBW0hpJncC1wO45HoOZWWnN6Qe5ETEs\n6fPAgxSnbO6MiKfmcgxmZmU212fvEBEPAA/M9euamdl5+EGumZnNHoe+mVmJzPllGKZC0iDwcgu/\nYhnw2gwN50Lhfc5f2fYXvM9T9asRMeE57+d16LdKUt/Zrj+RK+9z/sq2v+B9nkku75iZlYhD38ys\nRHIP/e3tHkAbeJ/zV7b9Be/zjMm6pm9mZmPlPtM3M7MGDn0zsxLJMvQlbZL0rKR+STe3ezwzRdJq\nSQ9LelrSU5K+kNqXStoj6fn0c0lql6Q70r/Dk5LWt3cPpk9SVdITku5P62skPZr27TvpAn5I6krr\n/Wl7TzvHPV2SFku6V9IzkvZLujz34yzpD9P/632S7pY0L7fjLGmnpCOS9jW0Tfm4StqS+j8vactU\nxpBd6DfckvEqYB1wnaR17R3VjBkGvhgR64ANwI1p324G9kbEWmBvWofi32BtemwD7pz7Ic+YLwD7\nG9a/AtwWEe8HjgJbU/tW4Ghqvy31uxDdDnwvIj4IfIRi37M9zpJWAr8P9EbEhyguyHgt+R3nbwKb\nmtqmdFwlLQVuBT5GcTfCW+tvFOckIrJ6AJcDDzas3wLc0u5xzdK+3kdxv+FngRWpbQXwbFr+O+C6\nhv6j/S6kB8V9F/YCnwDup7in/GtArfmYU1zB9fK0XEv91O59mOL+Xgy82DzunI8zZ+6qtzQdt/uB\nT+Z4nIEeYN90jytwHfB3De1j+k32yG6mzznckjEH6c/ZS4FHgeURcShtOgwsT8u5/Ft8DfgScDqt\nXwK8GRHDab1xv0b3OW0/lvpfSNYAg8A3Uknr65IWkvFxjoiDwN8ArwCHKI7b4+R9nOumelxbOt45\nhn72JC0C/gH4g4j4ReO2KN76szkPV9KngCMR8Xi7xzKHasB64M6IuBR4hzN/8gNZHuclwGaKN7z3\nAQsZXwbJ3lwc1xxDP+tbMkrqoAj8b0XEd1Pzq5JWpO0rgCOpPYd/iyuAz0h6Cfg2RYnndmCxpPr9\nIBr3a3Sf0/aLgdfncsAzYAAYiIhH0/q9FG8COR/n3wRejIjBiBgCvktx7HM+znVTPa4tHe8cQz/b\nWzJKErAD2B8RX23YtBuof4K/haLWX2+/Pp0FsAE41vBn5AUhIm6JiFUR0UNxLB+KiN8BHgY+m7o1\n73P93+Kzqf8FNSOOiMPAAUkfSE0bgafJ+DhTlHU2SFqQ/p/X9znb49xgqsf1QeBKSUvSX0hXprZz\n0+4PNWbpg5KrgeeAnwN/0u7xzOB+/QbFn35PAj9Jj6spapl7geeBHwBLU39RnMn0c+BnFGdGtH0/\nWtj/jwP3p+VfA34E9AP/F+hK7fPSen/a/mvtHvc09/WjQF861v8ELMn9OAN/DjwD7AP+D9CV23EG\n7qb4zGKI4i+6rdM5rsDvpX3vB26Yyhh8GQYzsxLJsbxjZmZn4dA3MysRh76ZWYk49M3MSsShb2ZW\nIg59M7MSceibmZXI/wei0CvT2nNGyAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Weight: [9.690797] Bias: [2.50584547]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}